{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Khiops Python samples_sklearn\n",
    "This is a notebook containing the code in the `samples_sklearn.py` script\nof the Khiops Python library.\n\nMake sure you have already installed the latest version of ",
    "[Khiops](https://khiops.org) before using this this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_classifier()`\n\n",
    "Trains a `.KhiopsClassifier` on a monotable dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset into a pandas dataframe\n",
    "adult_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "adult_df = pd.read_csv(adult_path, sep=\"\\t\")\n",
    "\n",
    "# Split the whole dataframe into train and test (70%-30%)\n",
    "adult_train_df, adult_test_df = train_test_split(\n",
    "    adult_df, test_size=0.3, random_state=1\n",
    ")\n",
    "\n",
    "# Split the dataset into:\n",
    "# - the X feature table\n",
    "# - the y target vector (\"class\" column)\n",
    "X_train = adult_train_df.drop(\"class\", axis=1)\n",
    "X_test = adult_test_df.drop(\"class\", axis=1)\n",
    "y_train = adult_train_df[\"class\"]\n",
    "y_test = adult_test_df[\"class\"]\n",
    "\n",
    "# Create the classifier object\n",
    "khc = KhiopsClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "khc.fit(X_train, y_train)\n",
    "\n",
    "# Predict the classes on the test dataset\n",
    "y_test_pred = khc.predict(X_test)\n",
    "print(\"Predicted classes (first 10):\")\n",
    "print(y_test_pred[0:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Predict the class probabilities on the test dataset\n",
    "y_test_probas = khc.predict_proba(X_test)\n",
    "print(f\"Class order: {khc.classes_}\")\n",
    "print(\"Predicted class probabilities (first 10):\")\n",
    "print(y_test_probas[0:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Evaluate accuracy and auc metrics on the test dataset\n",
    "test_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "test_auc = metrics.roc_auc_score(y_test, y_test_probas[:, 1])\n",
    "print(f\"Test accuracy = {test_accuracy}\")\n",
    "print(f\"Test auc      = {test_auc}\")\n",
    "\n",
    "# If you have Khiops Visualization installed you may open the report as follows\n",
    "# khc.export_report_file(\"report.khj\")\n",
    "# kh.visualize_report(\"report.khj\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_classifier_multiclass()`\n\n",
    "Trains a multiclass `.KhiopsClassifier` on a monotable dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset into a pandas dataframe\n",
    "iris_path = os.path.join(kh.get_samples_dir(), \"Iris\", \"Iris.txt\")\n",
    "iris_df = pd.read_csv(iris_path, sep=\"\\t\")\n",
    "\n",
    "# Split the whole dataframe into train and test (70%-30%)\n",
    "iris_train_df, iris_test_df = train_test_split(iris_df, test_size=0.3, random_state=1)\n",
    "\n",
    "# Split the dataset into:\n",
    "# - the X feature table\n",
    "# - the y target vector (\"Class\" column)\n",
    "X_train = iris_train_df.drop(\"Class\", axis=1)\n",
    "X_test = iris_test_df.drop(\"Class\", axis=1)\n",
    "y_train = iris_train_df[\"Class\"]\n",
    "y_test = iris_test_df[\"Class\"]\n",
    "\n",
    "# Create the classifier object\n",
    "khc = KhiopsClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "khc.fit(X_train, y_train)\n",
    "\n",
    "# Predict the classes on the test dataset\n",
    "y_test_pred = khc.predict(X_test)\n",
    "print(\"Predicted classes (first 10):\")\n",
    "print(y_test_pred[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Predict the class probabilities on the test datasets\n",
    "y_test_probas = khc.predict_proba(X_test)\n",
    "print(f\"Class order: {khc.classes_}\")\n",
    "print(\"Predicted class probabilities (first 10):\")\n",
    "print(y_test_probas[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Evaluate accuracy and auc metrics on the test dataset\n",
    "test_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "test_auc = metrics.roc_auc_score(y_test, y_test_probas, multi_class=\"ovr\")\n",
    "print(f\"Test accuracy = {test_accuracy}\")\n",
    "print(f\"Test auc      = {test_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_classifier_text()`\n\n",
    "Train a `.KhiopsClassifier` on a monotable dataframe with textual data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset into a pandas dataframe\n",
    "data_table_path = os.path.join(\n",
    "    kh.get_samples_dir(), \"NegativeAirlineTweets\", \"NegativeAirlineTweets.txt\"\n",
    ")\n",
    "data_df = pd.read_csv(data_table_path, sep=\"\\t\")\n",
    "\n",
    "# Split the whole dataframe into train and test (70%-30%)\n",
    "data_train_df, data_test_df = train_test_split(data_df, test_size=0.3, random_state=1)\n",
    "\n",
    "# Split the dataset into:\n",
    "# - the X feature table\n",
    "# - the y target vector (\"negativereason\" column)\n",
    "X_train = data_train_df.drop(\"negativereason\", axis=1)\n",
    "X_test = data_test_df.drop(\"negativereason\", axis=1)\n",
    "y_train = data_train_df[\"negativereason\"]\n",
    "y_test = data_test_df[\"negativereason\"]\n",
    "\n",
    "# Set Pandas StringDType on the \"text\" column\n",
    "X_train[\"text\"] = X_train[\"text\"].astype(\"string\")\n",
    "X_test[\"text\"] = X_test[\"text\"].astype(\"string\")\n",
    "\n",
    "# Create the classifier object\n",
    "khc = KhiopsClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "khc.fit(X_train, y_train)\n",
    "\n",
    "# Predict the classes on the test dataset\n",
    "y_test_pred = khc.predict(X_test)\n",
    "print(\"Predicted classes (first 10):\")\n",
    "print(y_test_pred[0:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Predict the class probabilities on the test dataset\n",
    "y_test_probas = khc.predict_proba(X_test)\n",
    "print(f\"Class order: {khc.classes_}\")\n",
    "print(\"Predicted class probabilities (first 10):\")\n",
    "print(y_test_probas[0:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Evaluate the accuracy metric on the test dataset\n",
    "test_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test accuracy = {test_accuracy}\")\n",
    "\n",
    "# If you have Khiops Visualization installed you may open the report as follows\n",
    "# khc.export_report_file(\"report.khj\")\n",
    "# kh.visualize_report(\"report.khj\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_classifier_multitable_star()`\n\n",
    "Trains a `.KhiopsClassifier` on a star multi-table dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsClassifier, train_test_split_dataset\n",
    "from sklearn import metrics\n",
    "\n",
    "# Load the dataset into pandas dataframes\n",
    "accidents_data_dir = os.path.join(kh.get_samples_dir(), \"AccidentsSummary\")\n",
    "accidents_df = pd.read_csv(\n",
    "    os.path.join(accidents_data_dir, \"Accidents.txt\"),\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "vehicles_df = pd.read_csv(os.path.join(accidents_data_dir, \"Vehicles.txt\"), sep=\"\\t\")\n",
    "\n",
    "# Create the dataset spec and the target\n",
    "X = {\n",
    "    \"main_table\": (accidents_df.drop(\"Gravity\", axis=1), [\"AccidentId\"]),\n",
    "    \"additional_data_tables\": {\n",
    "        \"Vehicles\": (vehicles_df, [\"AccidentId\", \"VehicleId\"]),\n",
    "    },\n",
    "}\n",
    "y = accidents_df[\"Gravity\"]\n",
    "\n",
    "# Split the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split_dataset(\n",
    "    X, y, test_size=0.3, random_state=1\n",
    ")\n",
    "\n",
    "# Train the classifier (by default it analyzes 100 multi-table features)\n",
    "khc = KhiopsClassifier()\n",
    "khc.fit(X_train, y_train)\n",
    "\n",
    "# Predict the class on the test dataset\n",
    "y_test_pred = khc.predict(X_test)\n",
    "print(\"Predicted classes (first 10):\")\n",
    "print(y_test_pred[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Predict the class probability on the test dataset\n",
    "y_test_probas = khc.predict_proba(X_test)\n",
    "print(f\"Class order: {khc.classes_}\")\n",
    "print(\"Predicted class probabilities (first 10):\")\n",
    "print(y_test_probas[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Evaluate accuracy and auc metrics on the test dataset\n",
    "test_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "test_auc = metrics.roc_auc_score(y_test, y_test_probas[:, 1])\n",
    "print(f\"Test accuracy = {test_accuracy}\")\n",
    "print(f\"Test auc      = {test_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_classifier_multitable_snowflake()`\n\n",
    "Trains a `.KhiopsClassifier` on a snowflake multi-table dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsClassifier, train_test_split_dataset\n",
    "from sklearn import metrics\n",
    "\n",
    "# Load the dataset tables into dataframes\n",
    "accidents_data_dir = os.path.join(kh.get_samples_dir(), \"Accidents\")\n",
    "accidents_df = pd.read_csv(os.path.join(accidents_data_dir, \"Accidents.txt\"), sep=\"\\t\")\n",
    "users_df = pd.read_csv(os.path.join(accidents_data_dir, \"Users.txt\"), sep=\"\\t\")\n",
    "vehicles_df = pd.read_csv(os.path.join(accidents_data_dir, \"Vehicles.txt\"), sep=\"\\t\")\n",
    "places_df = pd.read_csv(\n",
    "    os.path.join(accidents_data_dir, \"Places.txt\"), sep=\"\\t\", low_memory=False\n",
    ")\n",
    "\n",
    "# Build the multi-table dataset spec (drop the target column \"Gravity\")\n",
    "X = {\n",
    "    \"main_table\": (accidents_df.drop(\"Gravity\", axis=1), [\"AccidentId\"]),\n",
    "    \"additional_data_tables\": {\n",
    "        \"Vehicles\": (vehicles_df, [\"AccidentId\", \"VehicleId\"]),\n",
    "        \"Vehicles/Users\": (users_df, [\"AccidentId\", \"VehicleId\"]),\n",
    "        \"Places\": (places_df, [\"AccidentId\"], True),\n",
    "    },\n",
    "}\n",
    "\n",
    "# Load the target variable \"Gravity\"\n",
    "y = accidents_df[\"Gravity\"]\n",
    "\n",
    "# Split into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split_dataset(X, y)\n",
    "\n",
    "# Train the classifier (by default it creates 1000 multi-table features)\n",
    "khc = KhiopsClassifier(n_trees=0)\n",
    "khc.fit(X_train, y_train)\n",
    "\n",
    "# Predict the class on the test dataset\n",
    "y_test_pred = khc.predict(X_test)\n",
    "print(\"Predicted classes (first 10):\")\n",
    "print(y_test_pred[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Predict the class probability on the test dataset\n",
    "y_test_probas = khc.predict_proba(X_test)\n",
    "print(f\"Class order: {khc.classes_}\")\n",
    "print(\"Predicted class probabilities (first 10):\")\n",
    "print(y_test_probas[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Evaluate accuracy and auc metrics on the test dataset\n",
    "test_accuracy = metrics.accuracy_score(y_test_pred, y_test)\n",
    "test_auc = metrics.roc_auc_score(y_test, y_test_probas[:, 1])\n",
    "print(f\"Test accuracy = {test_accuracy}\")\n",
    "print(f\"Test auc      = {test_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_classifier_sparse()`\n\n",
    "Trains a `.KhiopsClassifier` on a monotable sparse matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from khiops.sklearn import KhiopsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# Load 3 classes of the 20newsgroups dataset\n",
    "categories = [\"comp.graphics\", \"sci.space\", \"misc.forsale\"]\n",
    "data_train, y_train = fetch_20newsgroups(\n",
    "    subset=\"train\",\n",
    "    categories=categories,\n",
    "    return_X_y=True,\n",
    ")\n",
    "data_test, y_test = fetch_20newsgroups(\n",
    "    subset=\"test\",\n",
    "    categories=categories,\n",
    "    return_X_y=True,\n",
    ")\n",
    "\n",
    "# Extract features from the training data using a sparse vectorizer\n",
    "vectorizer = HashingVectorizer(n_features=2**10, stop_words=\"english\")\n",
    "X_train = vectorizer.fit_transform(data_train)\n",
    "\n",
    "# Extract features from the test data using the same vectorizer\n",
    "X_test = vectorizer.transform(data_test)\n",
    "\n",
    "# Create the classifier object\n",
    "khc = KhiopsClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "khc.fit(X_train, y_train)\n",
    "\n",
    "# Predict the classes on the test dataset\n",
    "y_test_pred = khc.predict(X_test)\n",
    "print(\"Predicted classes (first 10):\")\n",
    "print(y_test_pred[0:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Predict the class probabilities on the test dataset\n",
    "y_test_probas = khc.predict_proba(X_test)\n",
    "print(f\"Class order: {khc.classes_}\")\n",
    "print(\"Predicted class probabilities (first 10):\")\n",
    "print(y_test_probas[0:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Evaluate accuracy and auc metrics on the test dataset\n",
    "test_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "test_auc = metrics.roc_auc_score(y_test, y_test_probas, multi_class=\"ovr\")\n",
    "print(f\"Test accuracy = {test_accuracy}\")\n",
    "print(f\"Test auc      = {test_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_classifier_pickle()`\n\n",
    "Shows the serialization and deserialization of a `.KhiopsClassifier`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsClassifier\n",
    "\n",
    "# Create/clean the output directory\n",
    "results_dir = os.path.join(\"kh_samples\", \"khiops_classifier_pickle\")\n",
    "khc_pickle_path = os.path.join(results_dir, \"khiops_classifier.pkl\")\n",
    "if os.path.exists(khc_pickle_path):\n",
    "    os.remove(khc_pickle_path)\n",
    "else:\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Load the \"Iris\" dataset\n",
    "iris_path = os.path.join(kh.get_samples_dir(), \"Iris\", \"Iris.txt\")\n",
    "iris_df = pd.read_csv(iris_path, sep=\"\\t\")\n",
    "X = iris_df.drop(\"Class\", axis=1)\n",
    "y = iris_df[\"Class\"]\n",
    "\n",
    "# Train the model with the Iris dataset\n",
    "khc = KhiopsClassifier()\n",
    "khc.fit(X, y)\n",
    "\n",
    "# Pickle its content to a file\n",
    "with open(khc_pickle_path, \"wb\") as khc_pickle_output_file:\n",
    "    pickle.dump(khc, khc_pickle_output_file)\n",
    "\n",
    "# Unpickle it\n",
    "with open(khc_pickle_path, \"rb\") as khc_pickle_file:\n",
    "    new_khc = pickle.load(khc_pickle_file)\n",
    "\n",
    "# Make some predictions on the training dataset with the unpickled classifier\n",
    "new_khc.predict(X)\n",
    "y_predicted = new_khc.predict(X)\n",
    "print(\"Predicted classes (first 10):\")\n",
    "print(y_predicted[:10])\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_classifier_with_hyperparameters()`\n\n",
    "Trains a `.KhiopsClassifier` on a star multi-table dataset\n    (advanced version with more hyperparameters)\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the root table of the dataset into a pandas dataframe\n",
    "accidents_dataset_path = os.path.join(kh.get_samples_dir(), \"AccidentsSummary\")\n",
    "accidents_df = pd.read_csv(\n",
    "    os.path.join(accidents_dataset_path, \"Accidents.txt\"),\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "\n",
    "# Split the root dataframe into train and test\n",
    "accidents_train_df, accidents_test_df = train_test_split(\n",
    "    accidents_df, test_size=0.3, random_state=1\n",
    ")\n",
    "\n",
    "# Obtain the main X feature table and the y target vector (\"Class\" column)\n",
    "y_train = accidents_train_df[\"Gravity\"]\n",
    "y_test = accidents_test_df[\"Gravity\"]\n",
    "X_train_main = accidents_train_df.drop(\"Gravity\", axis=1)\n",
    "X_test_main = accidents_test_df.drop(\"Gravity\", axis=1)\n",
    "\n",
    "# Load the secondary table of the dataset into a pandas dataframe\n",
    "vehicles_df = pd.read_csv(\n",
    "    os.path.join(accidents_dataset_path, \"Vehicles.txt\"), sep=\"\\t\"\n",
    ")\n",
    "\n",
    "# Split the secondary dataframe with the keys of the split root dataframe\n",
    "X_train_ids = X_train_main[\"AccidentId\"].to_frame()\n",
    "X_test_ids = X_test_main[\"AccidentId\"].to_frame()\n",
    "X_train_secondary = X_train_ids.merge(vehicles_df, on=\"AccidentId\")\n",
    "X_test_secondary = X_test_ids.merge(vehicles_df, on=\"AccidentId\")\n",
    "\n",
    "# Create the dataset multitable specification for the train/test split\n",
    "# We specify each table with a name and a tuple (dataframe, key_columns)\n",
    "X_train = {\n",
    "    \"main_table\": (X_train_main, [\"AccidentId\"]),\n",
    "    \"additional_data_tables\": {\n",
    "        \"Vehicles\": (X_train_secondary, [\"AccidentId\", \"VehicleId\"]),\n",
    "    },\n",
    "}\n",
    "X_test = {\n",
    "    \"main_table\": (X_test_main, [\"AccidentId\"]),\n",
    "    \"additional_data_tables\": {\n",
    "        \"Vehicles\": (X_test_secondary, [\"AccidentId\", \"VehicleId\"]),\n",
    "    },\n",
    "}\n",
    "# Train the classifier (by default it analyzes 100 multi-table features)\n",
    "khc = KhiopsClassifier(\n",
    "    n_features=20,\n",
    "    n_pairs=5,\n",
    "    n_trees=5,\n",
    "    n_selected_features=10,\n",
    "    n_evaluated_features=15,\n",
    "    specific_pairs=[(\"Light\", \"Weather\"), (\"Light\", \"IntersectionType\")],\n",
    "    all_possible_pairs=True,\n",
    "    construction_rules=[\"TableMode\", \"TableSelection\"],\n",
    "    group_target_value=False,\n",
    ")\n",
    "khc.fit(X_train, y_train)\n",
    "\n",
    "# Predict the class on the test dataset\n",
    "y_test_pred = khc.predict(X_test)\n",
    "print(\"Predicted classes (first 10):\")\n",
    "print(y_test_pred[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Predict the class probability on the test dataset\n",
    "y_test_probas = khc.predict_proba(X_test)\n",
    "print(f\"Class order: {khc.classes_}\")\n",
    "print(\"Predicted class probabilities (first 10):\")\n",
    "print(y_test_probas[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Evaluate accuracy and auc metrics on the test dataset\n",
    "test_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "test_auc = metrics.roc_auc_score(y_test, y_test_probas[:, 1])\n",
    "print(f\"Test accuracy = {test_accuracy}\")\n",
    "print(f\"Test auc      = {test_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_regressor()`\n\n",
    "Trains a `.KhiopsRegressor` on a monotable dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the \"Adult\" dataset and set the target to the \"age\" column\n",
    "adult_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "adult_df = pd.read_csv(adult_path, sep=\"\\t\")\n",
    "X = adult_df.drop(\"age\", axis=1)\n",
    "y = adult_df[\"age\"]\n",
    "\n",
    "# Split the whole dataframe into train and test (40%-60% for speed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "\n",
    "# Create the regressor object\n",
    "khr = KhiopsRegressor()\n",
    "\n",
    "# Train the regressor\n",
    "khr.fit(X_train, y_train)\n",
    "\n",
    "# Predict the values on the test dataset\n",
    "y_test_pred = khr.predict(X_test)\n",
    "print(\"Predicted values for 'age' (first 10):\")\n",
    "print(y_test_pred[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Evaluate R2 and MAE metrics on the test dataset\n",
    "test_r2 = metrics.r2_score(y_test, y_test_pred)\n",
    "test_mae = metrics.mean_absolute_error(y_test, y_test_pred)\n",
    "print(f\"Test R2  = {test_r2}\")\n",
    "print(f\"Test MAE = {test_mae}\")\n",
    "\n",
    "# If you have Khiops Visualization installed you may open the report as follows\n",
    "# khr.export_report_file(\"report.khj\")\n",
    "# kh.visualize_report(\"report.khj\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_encoder()`\n\n",
    "Trains a `.KhiopsEncoder` on a monotable dataframe\n\n    The Khiops encoder is a supervised feature encoder. It discretizes numerical\n    features and groups categorical features in a way that the resulting interval/groups\n    have the highest class-purity.\n\n    .. note::\n        For simplicity we train from the whole dataset. To assess the performance one\n        usually splits the dataset into train and test subsets.\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsEncoder\n",
    "\n",
    "# Load the dataset\n",
    "iris_path = os.path.join(kh.get_samples_dir(), \"Iris\", \"Iris.txt\")\n",
    "iris_df = pd.read_csv(iris_path, sep=\"\\t\")\n",
    "X = iris_df.drop(\"Class\", axis=1)\n",
    "y = iris_df[\"Class\"]\n",
    "\n",
    "# Create the encoder object\n",
    "khe = KhiopsEncoder(transform_type_numerical=\"part_label\")\n",
    "khe.fit(X, y)\n",
    "\n",
    "# Transform the training dataset\n",
    "X_transformed = khe.transform(X)\n",
    "\n",
    "# Print both the original and transformed features\n",
    "print(\"Original:\")\n",
    "print(X[:10])\n",
    "print(\"---\")\n",
    "print(\"Encoded feature names:\")\n",
    "print(khe.feature_names_out_)\n",
    "print(\"Encoded data:\")\n",
    "print(X_transformed[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# If you have Khiops Visualization installed you may open the report as follows\n",
    "# khe.export_report_file(\"report.khj\")\n",
    "# kh.visualize_report(\"report.khj\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_encoder_multitable_star()`\n\n",
    "Trains a `.KhiopsEncoder` on a star multi-table dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsEncoder\n",
    "\n",
    "# Load the dataset tables into dataframe\n",
    "accidents_data_dir = os.path.join(kh.get_samples_dir(), \"AccidentsSummary\")\n",
    "accidents_df = pd.read_csv(\n",
    "    os.path.join(accidents_data_dir, \"Accidents.txt\"),\n",
    "    sep=\"\\t\",\n",
    ")\n",
    "vehicles_df = pd.read_csv(os.path.join(accidents_data_dir, \"Vehicles.txt\"), sep=\"\\t\")\n",
    "\n",
    "# Build the multi-table dataset spec (drop the target column \"Gravity\")\n",
    "X = {\n",
    "    \"main_table\": (accidents_df.drop(\"Gravity\", axis=1), [\"AccidentId\"]),\n",
    "    \"additional_data_tables\": {\n",
    "        \"Vehicles\": (vehicles_df, [\"AccidentId\", \"VehicleId\"]),\n",
    "    },\n",
    "}\n",
    "\n",
    "# Load the target variable \"Gravity\"\n",
    "y = accidents_df[\"Gravity\"]\n",
    "\n",
    "# Create the KhiopsEncoder with 5 multitable features and fit it\n",
    "khe = KhiopsEncoder(n_features=10)\n",
    "khe.fit(X, y)\n",
    "\n",
    "# Transform the train dataset\n",
    "print(\"Encoded feature names:\")\n",
    "print(khe.feature_names_out_)\n",
    "print(\"Encoded data:\")\n",
    "print(khe.transform(X)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_encoder_multitable_snowflake()`\n\n",
    "Trains a `.KhiopsEncoder` on a snowflake multi-table dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsEncoder\n",
    "\n",
    "# Load the tables into dataframes\n",
    "accidents_data_dir = os.path.join(kh.get_samples_dir(), \"Accidents\")\n",
    "accidents_df = pd.read_csv(os.path.join(accidents_data_dir, \"Accidents.txt\"), sep=\"\\t\")\n",
    "users_df = pd.read_csv(os.path.join(accidents_data_dir, \"Users.txt\"), sep=\"\\t\")\n",
    "vehicles_df = pd.read_csv(os.path.join(accidents_data_dir, \"Vehicles.txt\"), sep=\"\\t\")\n",
    "places_df = pd.read_csv(\n",
    "    os.path.join(accidents_data_dir, \"Places.txt\"), sep=\"\\t\", low_memory=False\n",
    ")\n",
    "\n",
    "# Build the multi-table dataset spec (drop the target column \"Gravity\")\n",
    "X = {\n",
    "    \"main_table\": (accidents_df.drop(\"Gravity\", axis=1), [\"AccidentId\"]),\n",
    "    \"additional_data_tables\": {\n",
    "        \"Vehicles\": (vehicles_df, [\"AccidentId\", \"VehicleId\"]),\n",
    "        \"Vehicles/Users\": (users_df, [\"AccidentId\", \"VehicleId\"]),\n",
    "        \"Places\": (places_df, [\"AccidentId\"], True),\n",
    "    },\n",
    "}\n",
    "\n",
    "# Load the target variable \"Gravity\"\n",
    "y = accidents_df[\"Gravity\"]\n",
    "\n",
    "# Create the KhiopsEncoder with 10 additional multitable features and fit it\n",
    "khe = KhiopsEncoder(n_features=10)\n",
    "khe.fit(X, y)\n",
    "\n",
    "# Transform the train dataset\n",
    "print(\"Encoded feature names:\")\n",
    "print(khe.feature_names_out_)\n",
    "print(\"Encoded data:\")\n",
    "print(khe.transform(X)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_encoder_pipeline_with_hgbc()`\n\n",
    "Uses a `.KhiopsEncoder` with a `~sklearn.ensemble.HistGradientBoostingClassifier`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load the dataset into dataframes\n",
    "adult_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "adult_df = pd.read_csv(adult_path, sep=\"\\t\")\n",
    "X = adult_df.drop(\"class\", axis=1)\n",
    "y = adult_df[\"class\"]\n",
    "\n",
    "# Split the dataset into train and test (70%-30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Create the pipeline and fit it. Steps:\n",
    "# - The khiops supervised column encoder, generates a full-categorical table\n",
    "# - One hot encoder in all columns\n",
    "# - Train the HGB classifier\n",
    "pipe_steps = [\n",
    "    (\"khiops_enc\", KhiopsEncoder()),\n",
    "    (\n",
    "        \"onehot_enc\",\n",
    "        ColumnTransformer([], remainder=OneHotEncoder(sparse_output=False)),\n",
    "    ),\n",
    "    (\"hgb_clf\", HistGradientBoostingClassifier()),\n",
    "]\n",
    "pipe = Pipeline(pipe_steps)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Predict the classes on the test dataset\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "print(\"Predicted classes (first 10):\")\n",
    "print(y_test_pred[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Predict the class probabilities on the test dataset\n",
    "y_test_probas = pipe.predict_proba(X_test)\n",
    "print(\"Predicted class probabilities (first 10):\")\n",
    "print(y_test_probas[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Evaluate accuracy and auc metrics on the test dataset\n",
    "test_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "test_auc = metrics.roc_auc_score(y_test, y_test_probas[:, 1])\n",
    "print(f\"Test accuracy = {test_accuracy}\")\n",
    "print(f\"Test auc      = {test_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_encoder_with_hyperparameters()`\n\n",
    "Trains a `.KhiopsEncoder` on a star multi-table dataset\n    (advanced version with more hyperparameters)\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsEncoder\n",
    "\n",
    "# Load the tables into dataframes\n",
    "accidents_data_dir = os.path.join(kh.get_samples_dir(), \"AccidentsSummary\")\n",
    "accidents_df = pd.read_csv(os.path.join(accidents_data_dir, \"Accidents.txt\"), sep=\"\\t\")\n",
    "vehicles_df = pd.read_csv(os.path.join(accidents_data_dir, \"Vehicles.txt\"), sep=\"\\t\")\n",
    "\n",
    "# Build the multi-table dataset spec (drop the target column \"Gravity\")\n",
    "X = {\n",
    "    \"main_table\": (accidents_df.drop(\"Gravity\", axis=1), [\"AccidentId\"]),\n",
    "    \"additional_data_tables\": {\n",
    "        \"Vehicles\": (vehicles_df, [\"AccidentId\", \"VehicleId\"]),\n",
    "    },\n",
    "}\n",
    "\n",
    "# Load the target variable \"Gravity\"\n",
    "y = accidents_df[\"Gravity\"]\n",
    "\n",
    "# Create the KhiopsEncoder with 10 additional multitable features and fit it\n",
    "khe = KhiopsEncoder(\n",
    "    n_features=20,\n",
    "    n_pairs=5,\n",
    "    n_trees=5,\n",
    "    specific_pairs=[(\"Light\", \"Weather\"), (\"Light\", \"IntersectionType\")],\n",
    "    all_possible_pairs=True,\n",
    "    construction_rules=[\"TableMode\", \"TableSelection\"],\n",
    "    group_target_value=False,\n",
    "    informative_features_only=True,\n",
    "    keep_initial_variables=True,\n",
    "    transform_type_categorical=\"part_id\",\n",
    "    transform_type_numerical=\"part_id\",\n",
    "    transform_type_pairs=\"part_id\",\n",
    ")\n",
    "khe.fit(X, y)\n",
    "\n",
    "# Transform the train dataset\n",
    "print(\"Encoded feature names:\")\n",
    "print(khe.feature_names_out_)\n",
    "print(\"Encoded data:\")\n",
    "print(khe.transform(X)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_coclustering()`\n\n",
    "Trains a `.KhiopsCoclustering` on a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsCoclustering\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the secondary table of the dataset into a pandas dataframe\n",
    "splice_data_dir = os.path.join(kh.get_samples_dir(), \"SpliceJunction\")\n",
    "splice_dna_df = pd.read_csv(\n",
    "    os.path.join(splice_data_dir, \"SpliceJunctionDNA.txt\"), sep=\"\\t\"\n",
    ")\n",
    "\n",
    "# Train with only 70% of data (for speed in this example)\n",
    "X, _ = train_test_split(splice_dna_df, test_size=0.3, random_state=1)\n",
    "\n",
    "# Create the KhiopsCoclustering instance\n",
    "khcc = KhiopsCoclustering()\n",
    "\n",
    "# Train the model with the whole dataset\n",
    "khcc.fit(X, id_column=\"SampleId\")\n",
    "\n",
    "# Predict the clusters in some instances\n",
    "X_clusters = khcc.predict(X)\n",
    "print(\"Predicted clusters (first 10)\")\n",
    "print(X_clusters[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# If you have Khiops Co-Visualization installed you may open the report as follows\n",
    "# khcc.export_report_file(\"report.khcj\")\n",
    "# kh.visualize_report(\"report.khcj\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_coclustering_simplify()`\n\n",
    "Simplifies a `.KhiopsCoclustering` already trained on a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsCoclustering\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the secondary table of the dataset into a pandas dataframe\n",
    "splice_data_dir = os.path.join(kh.get_samples_dir(), \"SpliceJunction\")\n",
    "splice_dna_X = pd.read_csv(\n",
    "    os.path.join(splice_data_dir, \"SpliceJunctionDNA.txt\"), sep=\"\\t\"\n",
    ")\n",
    "\n",
    "# Train with only 70% of data (for speed in this example)\n",
    "X, _ = train_test_split(splice_dna_X, test_size=0.3, random_state=1)\n",
    "\n",
    "# Create the KhiopsCoclustering instance\n",
    "khcc = KhiopsCoclustering()\n",
    "\n",
    "# Train the model with the whole dataset\n",
    "khcc.fit(X, id_column=\"SampleId\")\n",
    "\n",
    "# Simplify coclustering along the individual ID dimension\n",
    "simplified_khcc = khcc.simplify(max_part_numbers={\"SampleId\": 3})\n",
    "\n",
    "# Predict the clusters using the simplified model\n",
    "X_clusters = simplified_khcc.predict(X)\n",
    "print(\"Predicted clusters (only three at most)\")\n",
    "print(X_clusters)\n",
    "print(\"---\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}