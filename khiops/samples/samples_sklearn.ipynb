{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Khiops Python samples_sklearn\n",
    "This is a notebook containing the code in the `samples_sklearn.py` script\nof the Khiops Python library.\n\nMake sure you have already installed the latest version of ",
    "[Khiops](https://khiops.org) before using this this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_classifier()`\n\n",
    "Trains a `.KhiopsClassifier` on a monotable dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset into a pandas dataframe\n",
    "adult_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "adult_df = pd.read_csv(adult_path, sep=\"\\t\")\n",
    "\n",
    "# Split the whole dataframe into train and test (70%-30%)\n",
    "adult_train_df, adult_test_df = train_test_split(\n",
    "    adult_df, test_size=0.3, random_state=1\n",
    ")\n",
    "\n",
    "# Split the dataset into:\n",
    "# - the X feature table\n",
    "# - the y target vector (\"class\" column)\n",
    "X_train = adult_train_df.drop(\"class\", axis=1)\n",
    "X_test = adult_test_df.drop(\"class\", axis=1)\n",
    "y_train = adult_train_df[\"class\"]\n",
    "y_test = adult_test_df[\"class\"]\n",
    "\n",
    "# Create the classifier object\n",
    "khc = KhiopsClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "khc.fit(X_train, y_train)\n",
    "\n",
    "# Show the feature importance info\n",
    "print(f\"Features evaluated: {khc.n_features_evaluated_}\")\n",
    "print(f\"Features selected : {khc.n_features_used_}\")\n",
    "print(\"Top 3 used features\")\n",
    "for i, feature in enumerate(khc.feature_used_names_[:3]):\n",
    "    print(f\"{feature} - Importance: {khc.feature_used_importances_[i][2]}\")\n",
    "print(\"---\")\n",
    "\n",
    "# Predict the classes on the test dataset\n",
    "y_test_pred = khc.predict(X_test)\n",
    "print(\"Predicted classes (first 10):\")\n",
    "print(y_test_pred[0:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Predict the class probabilities on the test dataset\n",
    "y_test_probas = khc.predict_proba(X_test)\n",
    "print(f\"Class order: {khc.classes_}\")\n",
    "print(\"Predicted class probabilities (first 10):\")\n",
    "print(y_test_probas[0:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Evaluate accuracy and auc metrics on the test dataset\n",
    "test_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "test_auc = metrics.roc_auc_score(y_test, y_test_probas[:, 1])\n",
    "print(f\"Test accuracy = {test_accuracy}\")\n",
    "print(f\"Test auc      = {test_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_classifier_multiclass()`\n\n",
    "Trains a multiclass `.KhiopsClassifier` on a monotable dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset into a pandas dataframe\n",
    "iris_path = os.path.join(kh.get_samples_dir(), \"Iris\", \"Iris.txt\")\n",
    "iris_df = pd.read_csv(iris_path, sep=\"\\t\")\n",
    "\n",
    "# Split the whole dataframe into train and test (70%-30%)\n",
    "iris_train_df, iris_test_df = train_test_split(iris_df, test_size=0.3, random_state=1)\n",
    "\n",
    "# Split the dataset into:\n",
    "# - the X feature table\n",
    "# - the y target vector (\"Class\" column)\n",
    "X_train = iris_train_df.drop(\"Class\", axis=1)\n",
    "X_test = iris_test_df.drop(\"Class\", axis=1)\n",
    "y_train = iris_train_df[\"Class\"]\n",
    "y_test = iris_test_df[\"Class\"]\n",
    "\n",
    "# Create the classifier object\n",
    "khc = KhiopsClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "khc.fit(X_train, y_train)\n",
    "\n",
    "# Predict the classes on the test dataset\n",
    "y_test_pred = khc.predict(X_test)\n",
    "print(\"Predicted classes (first 10):\")\n",
    "print(y_test_pred[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Predict the class probabilities on the test datasets\n",
    "y_test_probas = khc.predict_proba(X_test)\n",
    "print(f\"Class order: {khc.classes_}\")\n",
    "print(\"Predicted class probabilities (first 10):\")\n",
    "print(y_test_probas[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Evaluate accuracy and auc metrics on the test dataset\n",
    "test_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "test_auc = metrics.roc_auc_score(y_test, y_test_probas, multi_class=\"ovr\")\n",
    "print(f\"Test accuracy = {test_accuracy}\")\n",
    "print(f\"Test auc      = {test_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_classifier_multitable_star()`\n\n",
    "Trains a `.KhiopsClassifier` on a star multi-table dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsClassifier\n",
    "from khiops.utils.helpers import train_test_split_dataset\n",
    "from sklearn import metrics\n",
    "\n",
    "# Load the dataset into pandas dataframes\n",
    "accidents_data_dir = os.path.join(kh.get_samples_dir(), \"AccidentsSummary\")\n",
    "accidents_df = pd.read_csv(\n",
    "    os.path.join(accidents_data_dir, \"Accidents.txt\"),\n",
    "    sep=\"\\t\",\n",
    "    encoding=\"latin1\",\n",
    ")\n",
    "vehicles_df = pd.read_csv(os.path.join(accidents_data_dir, \"Vehicles.txt\"), sep=\"\\t\")\n",
    "\n",
    "# Create the dataset spec and the target\n",
    "X = {\n",
    "    \"main_table\": \"Accidents\",\n",
    "    \"tables\": {\n",
    "        \"Accidents\": (accidents_df.drop(\"Gravity\", axis=1), \"AccidentId\"),\n",
    "        \"Vehicles\": (vehicles_df, [\"AccidentId\", \"VehicleId\"]),\n",
    "    },\n",
    "}\n",
    "y = accidents_df[\"Gravity\"]\n",
    "\n",
    "# Split the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split_dataset(\n",
    "    X, y, test_size=0.3, random_state=1\n",
    ")\n",
    "\n",
    "# Train the classifier (by default it analyzes 100 multi-table features)\n",
    "khc = KhiopsClassifier()\n",
    "khc.fit(X_train, y_train)\n",
    "\n",
    "# Predict the class on the test dataset\n",
    "y_test_pred = khc.predict(X_test)\n",
    "print(\"Predicted classes (first 10):\")\n",
    "print(y_test_pred[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Predict the class probability on the test dataset\n",
    "y_test_probas = khc.predict_proba(X_test)\n",
    "print(f\"Class order: {khc.classes_}\")\n",
    "print(\"Predicted class probabilities (first 10):\")\n",
    "print(y_test_probas[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Evaluate accuracy and auc metrics on the test dataset\n",
    "test_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "test_auc = metrics.roc_auc_score(y_test, y_test_probas[:, 1])\n",
    "print(f\"Test accuracy = {test_accuracy}\")\n",
    "print(f\"Test auc      = {test_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_classifier_multitable_star_file()`\n\n",
    "Trains a `.KhiopsClassifier` with a file dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsClassifier\n",
    "from khiops.utils.helpers import train_test_split_dataset\n",
    "from sklearn import metrics\n",
    "\n",
    "# Create output directory\n",
    "results_dir = os.path.join(\"kh_samples\", \"khiops_classifier_multitable_star_file\")\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Create the dataset spec\n",
    "accidents_data_dir = os.path.join(kh.get_samples_dir(), \"AccidentsSummary\")\n",
    "X = {\n",
    "    \"main_table\": \"Accidents\",\n",
    "    \"tables\": {\n",
    "        \"Accidents\": (\n",
    "            os.path.join(accidents_data_dir, \"Accidents.txt\"),\n",
    "            \"AccidentId\",\n",
    "        ),\n",
    "        \"Vehicles\": (\n",
    "            os.path.join(accidents_data_dir, \"Vehicles.txt\"),\n",
    "            [\"AccidentId\", \"VehicleId\"],\n",
    "        ),\n",
    "    },\n",
    "    \"format\": (\"\\t\", True),\n",
    "}\n",
    "\n",
    "# Split the dataset into train and test\n",
    "X_train, X_test = train_test_split_dataset(\n",
    "    X, output_dir=os.path.join(results_dir, \"split\"), test_size=0.3\n",
    ")\n",
    "\n",
    "# Create the classifier and fit it\n",
    "khc = KhiopsClassifier(output_dir=results_dir)\n",
    "khc.fit(X_train, y=\"Gravity\")\n",
    "\n",
    "# Predict the class in addition to the class probabilities on the test dataset\n",
    "y_test_pred_path = khc.predict(X_test)\n",
    "y_test_pred = pd.read_csv(y_test_pred_path, sep=\"\\t\")\n",
    "print(\"Predicted classes (first 10):\")\n",
    "print(y_test_pred[\"PredictedGravity\"].head(10))\n",
    "print(\"---\")\n",
    "\n",
    "y_test_probas_path = khc.predict_proba(X_test)\n",
    "y_test_probas = pd.read_csv(y_test_probas_path, sep=\"\\t\")\n",
    "proba_columns = [col for col in y_test_probas if col.startswith(\"Prob\")]\n",
    "print(\"Predicted class probabilities (first 10):\")\n",
    "print(y_test_probas[proba_columns].head(10))\n",
    "print(\"---\")\n",
    "\n",
    "# Evaluate accuracy and auc metrics on the test dataset\n",
    "# Note: For roc_auc_score we have to use the \"greatest\" label which is \"NonLethal\"\n",
    "y_test = pd.read_csv(\n",
    "    X_test[\"tables\"][\"Accidents\"][0],\n",
    "    usecols=[\"Gravity\"],\n",
    "    sep=\"\\t\",\n",
    "    encoding=\"latin1\",\n",
    ")\n",
    "test_accuracy = metrics.accuracy_score(y_test, y_test_pred[\"PredictedGravity\"])\n",
    "test_auc = metrics.roc_auc_score(y_test, y_test_probas[\"ProbGravityNonLethal\"])\n",
    "print(f\"Test accuracy = {test_accuracy}\")\n",
    "print(f\"Test auc      = {test_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_classifier_multitable_snowflake()`\n\n",
    "Trains a `.KhiopsClassifier` on a snowflake multi-table dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsClassifier\n",
    "from khiops.utils.helpers import train_test_split_dataset\n",
    "from sklearn import metrics\n",
    "\n",
    "# Load the dataset tables into dataframes\n",
    "accidents_data_dir = os.path.join(kh.get_samples_dir(), \"Accidents\")\n",
    "accidents_df = pd.read_csv(\n",
    "    os.path.join(accidents_data_dir, \"Accidents.txt\"),\n",
    "    sep=\"\\t\",\n",
    "    encoding=\"latin1\",\n",
    ")\n",
    "users_df = pd.read_csv(\n",
    "    os.path.join(accidents_data_dir, \"Users.txt\"), sep=\"\\t\", encoding=\"latin1\"\n",
    ")\n",
    "vehicles_df = pd.read_csv(\n",
    "    os.path.join(accidents_data_dir, \"Vehicles.txt\"),\n",
    "    sep=\"\\t\",\n",
    "    encoding=\"latin1\",\n",
    ")\n",
    "places_df = pd.read_csv(\n",
    "    os.path.join(accidents_data_dir, \"Places.txt\"), sep=\"\\t\", encoding=\"latin1\"\n",
    ")\n",
    "\n",
    "# Create the dataset spec\n",
    "# Note: We discard the \"Gravity\" column from the \"Users\" table to avoid a target\n",
    "# leak. This is because the column was used to build the target.\n",
    "X = {\n",
    "    \"main_table\": \"Accidents\",\n",
    "    \"tables\": {\n",
    "        \"Accidents\": (accidents_df, \"AccidentId\"),\n",
    "        \"Vehicles\": (vehicles_df, [\"AccidentId\", \"VehicleId\"]),\n",
    "        \"Users\": (users_df.drop(\"Gravity\", axis=1), [\"AccidentId\", \"VehicleId\"]),\n",
    "        \"Places\": (places_df, [\"AccidentId\"]),\n",
    "    },\n",
    "    \"relations\": [\n",
    "        (\"Accidents\", \"Vehicles\"),\n",
    "        (\"Vehicles\", \"Users\"),\n",
    "        (\"Accidents\", \"Places\", True),\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Load the target variable \"Gravity\" from the \"AccidentsSummary\" dataset\n",
    "y = pd.read_csv(\n",
    "    os.path.join(kh.get_samples_dir(), \"AccidentsSummary\", \"Accidents.txt\"),\n",
    "    usecols=[\"Gravity\"],\n",
    "    sep=\"\\t\",\n",
    "    encoding=\"latin1\",\n",
    ").squeeze(\n",
    "    \"columns\"\n",
    ")  # squeeze to ensure pandas.Series\n",
    "\n",
    "# Split into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split_dataset(X, y)\n",
    "\n",
    "# Train the classifier (by default it creates 1000 multi-table features)\n",
    "khc = KhiopsClassifier(n_trees=0)\n",
    "khc.fit(X_train, y_train)\n",
    "\n",
    "# Show the feature importance info\n",
    "print(f\"Features evaluated: {khc.n_features_evaluated_}\")\n",
    "print(f\"Features selected : {khc.n_features_used_}\")\n",
    "print(\"Top 3 used features\")\n",
    "for i, feature in enumerate(khc.feature_used_names_[:3]):\n",
    "    print(f\"{feature} - Importance: {khc.feature_used_importances_[i][2]}\")\n",
    "print(\"---\")\n",
    "\n",
    "# Predict the class on the test dataset\n",
    "y_test_pred = khc.predict(X_test)\n",
    "print(\"Predicted classes (first 10):\")\n",
    "print(y_test_pred[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Predict the class probability on the test dataset\n",
    "y_test_probas = khc.predict_proba(X_test)\n",
    "print(f\"Class order: {khc.classes_}\")\n",
    "print(\"Predicted class probabilities (first 10):\")\n",
    "print(y_test_probas[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Evaluate accuracy and auc metrics on the test dataset\n",
    "test_accuracy = metrics.accuracy_score(y_test_pred, y_test)\n",
    "test_auc = metrics.roc_auc_score(y_test, y_test_probas[:, 1])\n",
    "print(f\"Test accuracy = {test_accuracy}\")\n",
    "print(f\"Test auc      = {test_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_classifier_sparse()`\n\n",
    "Trains a `.KhiopsClassifier` on a monotable sparse matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from khiops.sklearn import KhiopsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# Load 3 classes of the 20newsgroups dataset\n",
    "categories = [\"comp.graphics\", \"sci.space\", \"misc.forsale\"]\n",
    "data_train, y_train = fetch_20newsgroups(\n",
    "    subset=\"train\",\n",
    "    categories=categories,\n",
    "    return_X_y=True,\n",
    ")\n",
    "data_test, y_test = fetch_20newsgroups(\n",
    "    subset=\"test\",\n",
    "    categories=categories,\n",
    "    return_X_y=True,\n",
    ")\n",
    "\n",
    "# Extract features from the training data using a sparse vectorizer\n",
    "vectorizer = HashingVectorizer(n_features=2**10, stop_words=\"english\")\n",
    "X_train = vectorizer.fit_transform(data_train)\n",
    "\n",
    "# Extract features from the test data using the same vectorizer\n",
    "X_test = vectorizer.transform(data_test)\n",
    "\n",
    "# Create the classifier object\n",
    "khc = KhiopsClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "khc.fit(X_train, y_train)\n",
    "\n",
    "# Predict the classes on the test dataset\n",
    "y_test_pred = khc.predict(X_test)\n",
    "print(\"Predicted classes (first 10):\")\n",
    "print(y_test_pred[0:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Predict the class probabilities on the test dataset\n",
    "y_test_probas = khc.predict_proba(X_test)\n",
    "print(f\"Class order: {khc.classes_}\")\n",
    "print(\"Predicted class probabilities (first 10):\")\n",
    "print(y_test_probas[0:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Evaluate accuracy and auc metrics on the test dataset\n",
    "test_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "test_auc = metrics.roc_auc_score(y_test, y_test_probas, multi_class=\"ovr\")\n",
    "print(f\"Test accuracy = {test_accuracy}\")\n",
    "print(f\"Test auc      = {test_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_classifier_pickle()`\n\n",
    "Shows the serialization and deserialization of a `.KhiopsClassifier`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from khiops.sklearn import KhiopsClassifier\n",
    "\n",
    "# Create/clean the output directory\n",
    "results_dir = os.path.join(\"kh_samples\", \"khiops_classifier_pickle\")\n",
    "khc_pickle_path = os.path.join(results_dir, \"khiops_classifier.pkl\")\n",
    "if os.path.exists(khc_pickle_path):\n",
    "    os.remove(khc_pickle_path)\n",
    "else:\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Load the \"Iris\" dataset\n",
    "iris_path = os.path.join(kh.get_samples_dir(), \"Iris\", \"Iris.txt\")\n",
    "iris_df = pd.read_csv(iris_path, sep=\"\\t\")\n",
    "X = iris_df.drop(\"Class\", axis=1)\n",
    "y = iris_df[\"Class\"]\n",
    "\n",
    "# Train the model with the Iris dataset\n",
    "khc = KhiopsClassifier()\n",
    "khc.fit(X, y)\n",
    "\n",
    "# Pickle its content to a file\n",
    "with open(khc_pickle_path, \"wb\") as khc_pickle_output_file:\n",
    "    pickle.dump(khc, khc_pickle_output_file)\n",
    "\n",
    "# Unpickle it\n",
    "with open(khc_pickle_path, \"rb\") as khc_pickle_file:\n",
    "    new_khc = pickle.load(khc_pickle_file)\n",
    "\n",
    "# Make some predictions on the training dataset with the unpickled classifier\n",
    "new_khc.predict(X)\n",
    "y_predicted = new_khc.predict(X)\n",
    "print(\"Predicted classes (first 10):\")\n",
    "print(y_predicted[:10])\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_classifier_with_hyperparameters()`\n\n",
    "Trains a `.KhiopsClassifier` on a star multi-table dataset\n    (advanced version with more hyperparameters)\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the root table of the dataset into a pandas dataframe\n",
    "accidents_dataset_path = os.path.join(kh.get_samples_dir(), \"AccidentsSummary\")\n",
    "accidents_df = pd.read_csv(\n",
    "    os.path.join(accidents_dataset_path, \"Accidents.txt\"),\n",
    "    sep=\"\\t\",\n",
    "    encoding=\"latin1\",\n",
    ")\n",
    "\n",
    "# Split the root dataframe into train and test\n",
    "accidents_train_df, accidents_test_df = train_test_split(\n",
    "    accidents_df, test_size=0.3, random_state=1\n",
    ")\n",
    "\n",
    "# Obtain the main X feature table and the y target vector (\"Class\" column)\n",
    "y_train = accidents_train_df[\"Gravity\"]\n",
    "y_test = accidents_test_df[\"Gravity\"]\n",
    "X_train_main = accidents_train_df.drop(\"Gravity\", axis=1)\n",
    "X_test_main = accidents_test_df.drop(\"Gravity\", axis=1)\n",
    "\n",
    "# Load the secondary table of the dataset into a pandas dataframe\n",
    "vehicles_df = pd.read_csv(\n",
    "    os.path.join(accidents_dataset_path, \"Vehicles.txt\"), sep=\"\\t\"\n",
    ")\n",
    "\n",
    "# Split the secondary dataframe with the keys of the splitted root dataframe\n",
    "X_train_ids = X_train_main[\"AccidentId\"].to_frame()\n",
    "X_test_ids = X_test_main[\"AccidentId\"].to_frame()\n",
    "X_train_secondary = X_train_ids.merge(vehicles_df, on=\"AccidentId\")\n",
    "X_test_secondary = X_test_ids.merge(vehicles_df, on=\"AccidentId\")\n",
    "\n",
    "# Create the dataset multitable specification for the train/test split\n",
    "# We specify each table with a name and a tuple (dataframe, key_columns)\n",
    "X_train = {\n",
    "    \"main_table\": \"Accidents\",\n",
    "    \"tables\": {\n",
    "        \"Accidents\": (X_train_main, \"AccidentId\"),\n",
    "        \"Vehicles\": (X_train_secondary, [\"AccidentId\", \"VehicleId\"]),\n",
    "    },\n",
    "}\n",
    "X_test = {\n",
    "    \"main_table\": \"Accidents\",\n",
    "    \"tables\": {\n",
    "        \"Accidents\": (X_test_main, \"AccidentId\"),\n",
    "        \"Vehicles\": (X_test_secondary, [\"AccidentId\", \"VehicleId\"]),\n",
    "    },\n",
    "}\n",
    "# Train the classifier (by default it analyzes 100 multi-table features)\n",
    "khc = KhiopsClassifier(\n",
    "    n_features=20,\n",
    "    n_pairs=5,\n",
    "    n_trees=5,\n",
    "    n_selected_features=10,\n",
    "    n_evaluated_features=15,\n",
    "    specific_pairs=[(\"Light\", \"Weather\"), (\"Light\", \"IntersectionType\")],\n",
    "    all_possible_pairs=True,\n",
    "    construction_rules=[\"TableMode\", \"TableSelection\"],\n",
    "    group_target_value=False,\n",
    ")\n",
    "khc.fit(X_train, y_train)\n",
    "\n",
    "# Predict the class on the test dataset\n",
    "y_test_pred = khc.predict(X_test)\n",
    "print(\"Predicted classes (first 10):\")\n",
    "print(y_test_pred[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Predict the class probability on the test dataset\n",
    "y_test_probas = khc.predict_proba(X_test)\n",
    "print(f\"Class order: {khc.classes_}\")\n",
    "print(\"Predicted class probabilities (first 10):\")\n",
    "print(y_test_probas[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Evaluate accuracy and auc metrics on the test dataset\n",
    "test_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "test_auc = metrics.roc_auc_score(y_test, y_test_probas[:, 1])\n",
    "print(f\"Test accuracy = {test_accuracy}\")\n",
    "print(f\"Test auc      = {test_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_regressor()`\n\n",
    "Trains a `.KhiopsRegressor` on a monotable dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the \"Adult\" dataset and set the target to the \"age\" column\n",
    "adult_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "adult_df = pd.read_csv(adult_path, sep=\"\\t\")\n",
    "X = adult_df.drop(\"age\", axis=1)\n",
    "y = adult_df[\"age\"]\n",
    "\n",
    "# Split the whole dataframe into train and test (40%-60% for speed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "\n",
    "# Create the regressor object\n",
    "khr = KhiopsRegressor()\n",
    "\n",
    "# Train the regressor\n",
    "khr.fit(X_train, y_train)\n",
    "\n",
    "# Show the feature importance info\n",
    "print(f\"Features evaluated: {khr.n_features_evaluated_}\")\n",
    "print(f\"Features selected : {khr.n_features_used_}\")\n",
    "print(\"Top 3 used features\")\n",
    "for i, feature in enumerate(khr.feature_used_names_[:3]):\n",
    "    print(f\"{feature} - Importance: {khr.feature_used_importances_[i][2]}\")\n",
    "print(\"---\")\n",
    "\n",
    "# Predict the values on the test dataset\n",
    "y_test_pred = khr.predict(X_test)\n",
    "print(\"Predicted values for 'age' (first 10):\")\n",
    "print(y_test_pred[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Evaluate R2 and MAE metrics on the test dataset\n",
    "test_r2 = metrics.r2_score(y_test, y_test_pred)\n",
    "test_mae = metrics.mean_absolute_error(y_test, y_test_pred)\n",
    "print(f\"Test R2  = {test_r2}\")\n",
    "print(f\"Test MAE = {test_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_encoder()`\n\n",
    "Trains a `.KhiopsEncoder` on a monotable dataframe\n\n    The Khiops encoder is a supervised feature encoder. It discretizes numerical\n    features and groups categorical features in a way that the resulting interval/groups\n    have the highest class-purity.\n\n    .. note::\n        For simplicity we train from the whole dataset. To assess the performance one\n        usually splits the dataset into train and test subsets.\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from khiops.sklearn import KhiopsEncoder\n",
    "\n",
    "# Load the dataset\n",
    "iris_path = os.path.join(kh.get_samples_dir(), \"Iris\", \"Iris.txt\")\n",
    "iris_df = pd.read_csv(iris_path, sep=\"\\t\")\n",
    "X = iris_df.drop(\"Class\", axis=1)\n",
    "y = iris_df[\"Class\"]\n",
    "\n",
    "# Create the encoder object\n",
    "khe = KhiopsEncoder(transform_type_numerical=\"part_label\")\n",
    "khe.fit(X, y)\n",
    "\n",
    "# Transform the training dataset\n",
    "X_transformed = khe.transform(X)\n",
    "\n",
    "# Print both the original and transformed features\n",
    "print(\"Original:\")\n",
    "print(X[:10])\n",
    "print(\"---\")\n",
    "print(\"Encoded feature names:\")\n",
    "print(khe.feature_names_out_)\n",
    "print(\"Encoded data:\")\n",
    "print(X_transformed[:10])\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_encoder_multitable_star()`\n\n",
    "Trains a `.KhiopsEncoder` on a star multi-table dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsEncoder\n",
    "\n",
    "# Load the dataset tables into dataframe\n",
    "accidents_data_dir = os.path.join(kh.get_samples_dir(), \"AccidentsSummary\")\n",
    "accidents_df = pd.read_csv(\n",
    "    os.path.join(accidents_data_dir, \"Accidents.txt\"),\n",
    "    sep=\"\\t\",\n",
    "    encoding=\"latin1\",\n",
    ")\n",
    "vehicles_df = pd.read_csv(os.path.join(accidents_data_dir, \"Vehicles.txt\"), sep=\"\\t\")\n",
    "\n",
    "# Build the multi-table spec and the target\n",
    "X = {\n",
    "    \"main_table\": \"Accidents\",\n",
    "    \"tables\": {\n",
    "        \"Accidents\": (accidents_df.drop(\"Gravity\", axis=1), \"AccidentId\"),\n",
    "        \"Vehicles\": (vehicles_df, [\"AccidentId\", \"VehicleId\"]),\n",
    "    },\n",
    "}\n",
    "y = accidents_df[\"Gravity\"]\n",
    "\n",
    "# Create the KhiopsEncoder with 5 multitable features and fit it\n",
    "khe = KhiopsEncoder(n_features=10)\n",
    "khe.fit(X, y)\n",
    "\n",
    "# Transform the train dataset\n",
    "print(\"Encoded feature names:\")\n",
    "print(khe.feature_names_out_)\n",
    "print(\"Encoded data:\")\n",
    "print(khe.transform(X)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_encoder_multitable_snowflake()`\n\n",
    "Trains a `.KhiopsEncoder` on a snowflake multi-table dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsEncoder\n",
    "\n",
    "# Load the tables into dataframes\n",
    "accidents_data_dir = os.path.join(kh.get_samples_dir(), \"Accidents\")\n",
    "accidents_df = pd.read_csv(\n",
    "    os.path.join(accidents_data_dir, \"Accidents.txt\"),\n",
    "    sep=\"\\t\",\n",
    "    encoding=\"latin1\",\n",
    ")\n",
    "places_df = pd.read_csv(\n",
    "    os.path.join(accidents_data_dir, \"Places.txt\"), sep=\"\\t\", encoding=\"latin1\"\n",
    ")\n",
    "users_df = pd.read_csv(\n",
    "    os.path.join(accidents_data_dir, \"Users.txt\"), sep=\"\\t\", encoding=\"latin1\"\n",
    ")\n",
    "vehicles_df = pd.read_csv(\n",
    "    os.path.join(accidents_data_dir, \"Vehicles.txt\"),\n",
    "    sep=\"\\t\",\n",
    "    encoding=\"latin1\",\n",
    ")\n",
    "\n",
    "# Build the multi-table spec\n",
    "# Note: We discard the \"Gravity\" field from the \"Users\" table as it was used to\n",
    "# build the target column\n",
    "X = {\n",
    "    \"main_table\": \"Accidents\",\n",
    "    \"tables\": {\n",
    "        \"Accidents\": (accidents_df, \"AccidentId\"),\n",
    "        \"Places\": (places_df, \"AccidentId\"),\n",
    "        \"Vehicles\": (vehicles_df, [\"AccidentId\", \"VehicleId\"]),\n",
    "        \"Users\": (users_df.drop(\"Gravity\", axis=1), [\"AccidentId\", \"VehicleId\"]),\n",
    "    },\n",
    "    \"relations\": [\n",
    "        (\"Accidents\", \"Vehicles\"),\n",
    "        (\"Accidents\", \"Places\", True),\n",
    "        (\"Vehicles\", \"Users\"),\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Load the target variable from the AccidentsSummary dataset\n",
    "y = pd.read_csv(\n",
    "    os.path.join(kh.get_samples_dir(), \"AccidentsSummary\", \"Accidents.txt\"),\n",
    "    usecols=[\"Gravity\"],\n",
    "    sep=\"\\t\",\n",
    "    encoding=\"latin1\",\n",
    ").squeeze(\n",
    "    \"columns\"\n",
    ")  # squeeze to ensure pandas.Series\n",
    "\n",
    "# Create the KhiopsEncoder with 10 additional multitable features and fit it\n",
    "khe = KhiopsEncoder(n_features=10)\n",
    "khe.fit(X, y)\n",
    "\n",
    "# Show the feature importance info\n",
    "print(f\"Features evaluated: {khe.n_features_evaluated_}\")\n",
    "print(\"Top 3 evaluated features\")\n",
    "for i, feature in enumerate(khe.feature_evaluated_names_[:3]):\n",
    "    print(f\"{feature} - Level: {khe.feature_evaluated_importances_[i]}\")\n",
    "print(\"---\")\n",
    "\n",
    "# Transform the train dataset\n",
    "print(\"Encoded feature names:\")\n",
    "print(khe.feature_names_out_)\n",
    "print(\"Encoded data:\")\n",
    "print(khe.transform(X)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_encoder_pipeline_with_hgbc()`\n\n",
    "Uses a `.KhiopsEncoder` with a `~sklearn.ensemble.HistGradientBoostingClassifier`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load the dataset into dataframes\n",
    "adult_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "adult_df = pd.read_csv(adult_path, sep=\"\\t\")\n",
    "X = adult_df.drop(\"class\", axis=1)\n",
    "y = adult_df[\"class\"]\n",
    "\n",
    "# Split the dataset into train and test (70%-30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Create the pipeline and fit it. Steps:\n",
    "# - The khiops supervised column encoder, generates a full-categorical table\n",
    "# - One hot encoder in all columns\n",
    "# - Train the HGB classifier\n",
    "pipe_steps = [\n",
    "    (\"khiops_enc\", KhiopsEncoder()),\n",
    "    (\n",
    "        \"onehot_enc\",\n",
    "        ColumnTransformer([], remainder=OneHotEncoder(sparse_output=False)),\n",
    "    ),\n",
    "    (\"hgb_clf\", HistGradientBoostingClassifier()),\n",
    "]\n",
    "pipe = Pipeline(pipe_steps)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Predict the classes on the test dataset\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "print(\"Predicted classes (first 10):\")\n",
    "print(y_test_pred[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Predict the class probabilities on the test dataset\n",
    "y_test_probas = pipe.predict_proba(X_test)\n",
    "print(\"Predicted class probabilities (first 10):\")\n",
    "print(y_test_probas[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Evaluate accuracy and auc metrics on the test dataset\n",
    "test_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "test_auc = metrics.roc_auc_score(y_test, y_test_probas[:, 1])\n",
    "print(f\"Test accuracy = {test_accuracy}\")\n",
    "print(f\"Test auc      = {test_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_encoder_with_hyperparameters()`\n\n",
    "Trains a `.KhiopsEncoder` on a star multi-table dataset\n    (advanced version with more hyperparameters)\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsEncoder\n",
    "\n",
    "# Load the root table of the dataset into a pandas dataframe\n",
    "accidents_dataset_path = os.path.join(kh.get_samples_dir(), \"AccidentsSummary\")\n",
    "accidents_df = pd.read_csv(\n",
    "    os.path.join(accidents_dataset_path, \"Accidents.txt\"),\n",
    "    sep=\"\\t\",\n",
    "    encoding=\"latin1\",\n",
    ")\n",
    "\n",
    "# Obtain the root X feature table and the y target vector (\"Class\" column)\n",
    "X_main = accidents_df.drop(\"Gravity\", axis=1)\n",
    "y = accidents_df[\"Gravity\"]\n",
    "\n",
    "# Load the secondary table of the dataset into a pandas dataframe\n",
    "X_secondary = pd.read_csv(\n",
    "    os.path.join(accidents_dataset_path, \"Vehicles.txt\"), sep=\"\\t\"\n",
    ")\n",
    "\n",
    "# Create the dataset multitable specification for the train/test split\n",
    "# We specify each table with a name and a tuple (dataframe, key_columns)\n",
    "X_dataset = {\n",
    "    \"main_table\": \"Accidents\",\n",
    "    \"tables\": {\n",
    "        \"Accidents\": (X_main, \"AccidentId\"),\n",
    "        \"Vehicles\": (X_secondary, [\"AccidentId\", \"VehicleId\"]),\n",
    "    },\n",
    "}\n",
    "\n",
    "# Create the KhiopsEncoder with 10 additional multitable features and fit it\n",
    "khe = KhiopsEncoder(\n",
    "    n_features=20,\n",
    "    n_pairs=5,\n",
    "    n_trees=5,\n",
    "    specific_pairs=[(\"Light\", \"Weather\"), (\"Light\", \"IntersectionType\")],\n",
    "    all_possible_pairs=True,\n",
    "    construction_rules=[\"TableMode\", \"TableSelection\"],\n",
    "    group_target_value=False,\n",
    "    informative_features_only=True,\n",
    "    keep_initial_variables=True,\n",
    "    transform_type_categorical=\"part_id\",\n",
    "    transform_type_numerical=\"part_id\",\n",
    "    transform_pairs=\"part_id\",\n",
    ")\n",
    "khe.fit(X_dataset, y)\n",
    "\n",
    "# Transform the train dataset\n",
    "print(\"Encoded feature names:\")\n",
    "print(khe.feature_names_out_)\n",
    "print(\"Encoded data:\")\n",
    "print(khe.transform(X_dataset)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_coclustering()`\n\n",
    "Trains a `.KhiopsCoclustering` on a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsCoclustering\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the secondary table of the dataset into a pandas dataframe\n",
    "splice_data_dir = os.path.join(kh.get_samples_dir(), \"SpliceJunction\")\n",
    "splice_dna_df = pd.read_csv(\n",
    "    os.path.join(splice_data_dir, \"SpliceJunctionDNA.txt\"), sep=\"\\t\"\n",
    ")\n",
    "\n",
    "# Train with only 70% of data (for speed in this example)\n",
    "X, _ = train_test_split(splice_dna_df, test_size=0.3, random_state=1)\n",
    "\n",
    "# Create the KhiopsCoclustering instance\n",
    "khcc = KhiopsCoclustering()\n",
    "\n",
    "# Train the model with the whole dataset\n",
    "khcc.fit(X, id_column=\"SampleId\")\n",
    "\n",
    "# Predict the clusters in some instances\n",
    "X_clusters = khcc.predict(X)\n",
    "print(\"Predicted clusters (first 10)\")\n",
    "print(X_clusters[:10])\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_coclustering_simplify()`\n\n",
    "Simplifies a `.KhiopsCoclustering` already trained on a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsCoclustering\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the secondary table of the dataset into a pandas dataframe\n",
    "splice_data_dir = os.path.join(kh.get_samples_dir(), \"SpliceJunction\")\n",
    "splice_dna_X = pd.read_csv(\n",
    "    os.path.join(splice_data_dir, \"SpliceJunctionDNA.txt\"), sep=\"\\t\"\n",
    ")\n",
    "\n",
    "# Train with only 70% of data (for speed in this example)\n",
    "X, _ = train_test_split(splice_dna_X, test_size=0.3, random_state=1)\n",
    "\n",
    "# Create the KhiopsCoclustering instance\n",
    "khcc = KhiopsCoclustering()\n",
    "\n",
    "# Train the model with the whole dataset\n",
    "khcc.fit(X, id_column=\"SampleId\")\n",
    "\n",
    "# Simplify coclustering along the individual ID dimension\n",
    "simplified_khcc = khcc.simplify(max_part_numbers={\"SampleId\": 3})\n",
    "\n",
    "# Predict the clusters using the simplified model\n",
    "X_clusters = simplified_khcc.predict(X)\n",
    "print(\"Predicted clusters (only three at most)\")\n",
    "print(X_clusters)\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `khiops_classifier_multitable_list()`\n\n",
    "Trains a KhiopsClassifier using a list dataset specification\n\n    .. warning::\n        This dataset input method is **Deprecated** and will be removed in Khiops 11.\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from khiops import core as kh\n",
    "from khiops.sklearn import KhiopsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the root table of the dataset into a pandas dataframe\n",
    "accidents_data_dir = os.path.join(kh.get_samples_dir(), \"AccidentsSummary\")\n",
    "accidents_df = pd.read_csv(\n",
    "    os.path.join(accidents_data_dir, \"Accidents.txt\"),\n",
    "    sep=\"\\t\",\n",
    "    encoding=\"latin1\",\n",
    ")\n",
    "X = accidents_df.drop(\"Gravity\", axis=1)\n",
    "y = accidents_df[\"Gravity\"]\n",
    "\n",
    "# Split the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Load the secondary table of the dataset into a pandas dataframe\n",
    "vehicles_df = pd.read_csv(os.path.join(accidents_data_dir, \"Vehicles.txt\"), sep=\"\\t\")\n",
    "\n",
    "# Split the secondary dataframe with the keys of the splitted root dataframe\n",
    "X_train_ids = X_train[\"AccidentId\"].to_frame()\n",
    "X_test_ids = X_test[\"AccidentId\"].to_frame()\n",
    "X_train_secondary = X_train_ids.merge(vehicles_df, on=\"AccidentId\")\n",
    "X_test_secondary = X_test_ids.merge(vehicles_df, on=\"AccidentId\")\n",
    "\n",
    "# Create the classifier specifying the key column name\n",
    "khc = KhiopsClassifier(key=\"AccidentId\")\n",
    "\n",
    "# Train the classifier\n",
    "khc.fit([X_train, X_train_secondary], y_train)\n",
    "\n",
    "# Predict the class on the test dataset\n",
    "y_test_pred = khc.predict([X_test, X_test_secondary])\n",
    "print(\"Predicted classes (first 10):\")\n",
    "print(y_test_pred[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Predict the class probability on the test dataset\n",
    "y_test_probas = khc.predict_proba([X_test, X_test_secondary])\n",
    "print(\"Predicted class probabilities (first 10):\")\n",
    "print(y_test_probas[:10])\n",
    "print(\"---\")\n",
    "\n",
    "# Evaluate accuracy and auc metrics on the test dataset\n",
    "test_accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "test_auc = metrics.roc_auc_score(y_test, y_test_probas[:, 1])\n",
    "print(f\"Test accuracy = {test_accuracy}\")\n",
    "print(f\"Test auc      = {test_auc}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}