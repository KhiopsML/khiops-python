{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Khiops Python samples\n",
    "This is a notebook containing the code in the `samples.py` script\nof the Khiops Python library.\n\nMake sure you have already installed the latest version of ",
    "[Khiops](https://khiops.org) before using this this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_khiops_version()`\n\n",
    "Shows the Khiops version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Khiops version: {kh.get_khiops_version()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `build_dictionary_from_data_table()`\n\n",
    "Automatically creates a dictionary file from a data table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "data_table_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "dictionary_name = \"AutoAdult\"\n",
    "dictionary_file_path = os.path.join(\n",
    "    \"kh_samples\", \"build_dictionary_from_data_table\", \"AutoAdult.kdic\"\n",
    ")\n",
    "\n",
    "# Create the dictionary from the data table\n",
    "kh.build_dictionary_from_data_table(\n",
    "    data_table_path, dictionary_name, dictionary_file_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `detect_data_table_format()`\n\n",
    "Detects the format of a data table with and without a dictionary file\n\n    The user may provide a dictionary file or dictionary domain object specifying the\n    table schema. The detection heuristic is more accurate with this information.\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "data_table_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "dictionary_file_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.kdic\")\n",
    "output_dir = os.path.join(\"kh_samples\", \"detect_data_table_format\")\n",
    "transformed_data_table_path = os.path.join(output_dir, \"AdultWithAnotherFormat.txt\")\n",
    "\n",
    "# Create the output directory\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "# Detect the format of the table\n",
    "format_spec = kh.detect_data_table_format(data_table_path)\n",
    "print(\"Format specification (header_line, field_separator)\")\n",
    "print(\"Format detected on original table:\", format_spec)\n",
    "\n",
    "# Make a deployment to change the format of the data table\n",
    "kh.deploy_model(\n",
    "    dictionary_file_path,\n",
    "    \"Adult\",\n",
    "    data_table_path,\n",
    "    transformed_data_table_path,\n",
    "    output_header_line=False,\n",
    "    output_field_separator=\",\",\n",
    ")\n",
    "\n",
    "# Detect the new format of the table without a dictionary file\n",
    "format_spec = kh.detect_data_table_format(transformed_data_table_path)\n",
    "print(\"Format detected on reformatted table:\", format_spec)\n",
    "\n",
    "# Detect the new format of the table with a dictionary file\n",
    "format_spec = kh.detect_data_table_format(\n",
    "    transformed_data_table_path,\n",
    "    dictionary_file_path_or_domain=dictionary_file_path,\n",
    "    dictionary_name=\"Adult\",\n",
    ")\n",
    "print(\"Format detected (with dictionary file) on reformatted table:\", format_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `check_database()`\n\n",
    "Runs an integrity check of a database\n\n    The results are stored in the specified log file with at most 50 error messages.\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "dictionary_file_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.kdic\")\n",
    "data_table_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "log_file = os.path.join(\"kh_samples\", \"check_database\", \"check_database.log\")\n",
    "\n",
    "# Check the database\n",
    "kh.check_database(\n",
    "    dictionary_file_path,\n",
    "    \"Adult\",\n",
    "    data_table_path,\n",
    "    log_file_path=log_file,\n",
    "    max_messages=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `export_dictionary_files()`\n\n",
    "Exports a customized dictionary to \".kdic\" and to \".kdicj\" (JSON)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "dictionary_file_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.kdic\")\n",
    "output_dir = os.path.join(\"kh_samples\", \"export_dictionary_file\")\n",
    "output_dictionary_file_path = os.path.join(output_dir, \"ModifiedAdult.kdic\")\n",
    "output_dictionary_json_path = os.path.join(output_dir, \"ModifiedAdult.kdicj\")\n",
    "alt_output_dictionary_json_path = os.path.join(output_dir, \"AltModifiedAdult.kdicj\")\n",
    "\n",
    "# Load the dictionary domain from initial dictionary file\n",
    "# Then obtain the \"Adult\" dictionary within\n",
    "domain = kh.read_dictionary_file(dictionary_file_path)\n",
    "dictionary = domain.get_dictionary(\"Adult\")\n",
    "\n",
    "# Set some of its variables to unused\n",
    "fnlwgt_variable = dictionary.get_variable(\"fnlwgt\")\n",
    "fnlwgt_variable.used = False\n",
    "label_variable = dictionary.get_variable(\"Label\")\n",
    "label_variable.used = False\n",
    "\n",
    "# Create output directory if necessary\n",
    "if not os.path.exists(\"kh_samples\"):\n",
    "    os.mkdir(\"kh_samples\")\n",
    "    os.mkdir(output_dir)\n",
    "else:\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "# Export to kdic\n",
    "domain.export_khiops_dictionary_file(output_dictionary_file_path)\n",
    "\n",
    "# Export to kdicj either from the domain or from a kdic file\n",
    "# Requires a Khiops execution, that's why it is not a method of DictionaryDomain\n",
    "kh.export_dictionary_as_json(domain, output_dictionary_json_path)\n",
    "kh.export_dictionary_as_json(\n",
    "    output_dictionary_file_path, alt_output_dictionary_json_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_predictor()`\n\n",
    "Trains a predictor with a minimal setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "dictionary_file_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.kdic\")\n",
    "data_table_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "analysis_report_file_path = os.path.join(\n",
    "    \"kh_samples\", \"train_predictor\", \"AnalysisReport.khj\"\n",
    ")\n",
    "\n",
    "# Train the predictor\n",
    "kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"Adult\",\n",
    "    data_table_path,\n",
    "    \"class\",\n",
    "    analysis_report_file_path,\n",
    "    max_trees=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_predictor_file_paths()`\n\n",
    "Trains a predictor and stores the return value of the function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "dictionary_file_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.kdic\")\n",
    "data_table_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "report_file_path = os.path.join(\n",
    "    \"kh_samples\", \"train_predictor_file_paths\", \"AnalysisResults.khj\"\n",
    ")\n",
    "\n",
    "# Train the predictor\n",
    "_, modeling_dictionary_file_path = kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"Adult\",\n",
    "    data_table_path,\n",
    "    \"class\",\n",
    "    report_file_path,\n",
    "    max_trees=0,\n",
    ")\n",
    "print(\"Reports file available at \" + report_file_path)\n",
    "print(\"Modeling dictionary file available at \" + modeling_dictionary_file_path)\n",
    "\n",
    "# If you have Khiops Visualization installed you may open the report as follows\n",
    "# kh.visualize_report(report_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_predictor_text()`\n\n",
    "Trains a predictor with just text-specific parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "dictionary_file_path = os.path.join(\n",
    "    kh.get_samples_dir(), \"NegativeAirlineTweets\", \"NegativeAirlineTweets.kdic\"\n",
    ")\n",
    "data_table_path = os.path.join(\n",
    "    kh.get_samples_dir(), \"NegativeAirlineTweets\", \"NegativeAirlineTweets.txt\"\n",
    ")\n",
    "report_file_path = os.path.join(\n",
    "    \"kh_samples\", \"train_predictor_text\", \"AnalysisResults.khj\"\n",
    ")\n",
    "\n",
    "# Train the predictor\n",
    "kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"FlightNegativeTweets\",\n",
    "    data_table_path,\n",
    "    \"negativereason\",\n",
    "    report_file_path,\n",
    "    max_trees=5,\n",
    "    max_text_features=1000,\n",
    "    text_features=\"words\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_predictor_error_handling()`\n\n",
    "Shows how to handle errors when training a predictor\n\n    Trains the predictor and handles the errors by printing a custom message. When the\n    Khiops application fails the Khiops Python library will raise a\n    KhiopsRuntimeError reporting the errors encountered by Khiops.\n\n    If the latter information is not enough to diagnose the problem, it is possible to\n    save the temporary log file by activating the \"trace\" flag in the call to\n    `~.api.train_predictor`. The path of the log file will be printed to the standard\n    output, as well as that of the dictionary and scenario files (note that the \"trace\"\n    keyword argument is available in all functions of the `khiops.core.api`\n    submodule).\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths with a nonexistent dictionary file\n",
    "dictionary_file_path = \"NONEXISTENT_DICTIONARY_FILE.kdic\"\n",
    "data_table_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "output_dir = os.path.join(\"kh_samples\", \"train_predictor_error_handling\")\n",
    "report_file_path = os.path.join(output_dir, \"AnalysisResults.khj\")\n",
    "log_file_path = os.path.join(output_dir, \"khiops.log\")\n",
    "scenario_path = os.path.join(output_dir, \"scenario._kh\")\n",
    "\n",
    "# Train the predictor and handle the error\n",
    "try:\n",
    "    kh.train_predictor(\n",
    "        dictionary_file_path,\n",
    "        \"Adult\",\n",
    "        data_table_path,\n",
    "        \"class\",\n",
    "        report_file_path,\n",
    "        trace=True,\n",
    "        log_file_path=log_file_path,\n",
    "        output_scenario_path=scenario_path,\n",
    "    )\n",
    "except kh.KhiopsRuntimeError as error:\n",
    "    print(\"Khiops training failed! Below the KhiopsRuntimeError message:\")\n",
    "    print(error)\n",
    "\n",
    "print(\"\\nFull log contents:\")\n",
    "print(\"------------------\")\n",
    "with open(log_file_path) as log_file:\n",
    "    for line in log_file:\n",
    "        print(line, end=\"\")\n",
    "\n",
    "print(\"\\nExecuted scenario\")\n",
    "print(\"-----------------\")\n",
    "with open(scenario_path) as scenario_file:\n",
    "    for line in scenario_file:\n",
    "        print(line, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_predictor_mt()`\n\n",
    "Trains a multi-table predictor in the simplest way possible\n\n    It is a call to `~.api.train_predictor` with additional parameters to handle\n    multi-table learning\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "accidents_dir = os.path.join(kh.get_samples_dir(), \"AccidentsSummary\")\n",
    "dictionary_file_path = os.path.join(accidents_dir, \"Accidents.kdic\")\n",
    "accidents_table_path = os.path.join(accidents_dir, \"Accidents.txt\")\n",
    "vehicles_table_path = os.path.join(accidents_dir, \"Vehicles.txt\")\n",
    "report_file_path = os.path.join(\n",
    "    \"kh_samples\", \"train_predictor_mt\", \"AnalysisResults.khj\"\n",
    ")\n",
    "\n",
    "# Train the predictor. Besides the mandatory parameters, we specify:\n",
    "# - A python dictionary linking data paths to file paths for non-root tables\n",
    "# - To not construct any decision tree\n",
    "# The default number of automatic features is 100\n",
    "kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"Accident\",\n",
    "    accidents_table_path,\n",
    "    \"Gravity\",\n",
    "    report_file_path,\n",
    "    additional_data_tables={\"Vehicles\": vehicles_table_path},\n",
    "    max_trees=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_predictor_mt_with_specific_rules()`\n\n",
    "Trains a multi-table predictor with specific construction rules\n\n    It is the same as `.train_predictor_mt` but with the specification of the allowed\n    variable construction rules. The list of available rules is found in the field\n    ``kh.all_construction_rules``\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "accidents_dir = os.path.join(kh.get_samples_dir(), \"AccidentsSummary\")\n",
    "dictionary_file_path = os.path.join(accidents_dir, \"Accidents.kdic\")\n",
    "accidents_table_path = os.path.join(accidents_dir, \"Accidents.txt\")\n",
    "vehicles_table_path = os.path.join(accidents_dir, \"Vehicles.txt\")\n",
    "report_file_path = os.path.join(\n",
    "    \"kh_samples\",\n",
    "    \"train_predictor_mt_with_specific_rules\",\n",
    "    \"AnalysisResults.khj\",\n",
    ")\n",
    "\n",
    "# Train the predictor. Besides the mandatory parameters, it is specified:\n",
    "# - A python dictionary linking data paths to file paths for non-root tables\n",
    "# - The maximum number of aggregate variables to construct (1000)\n",
    "# - The construction rules allowed to automatically create aggregates\n",
    "# - To not construct any decision tree\n",
    "kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"Accident\",\n",
    "    accidents_table_path,\n",
    "    \"Gravity\",\n",
    "    report_file_path,\n",
    "    additional_data_tables={\"Vehicles\": vehicles_table_path},\n",
    "    max_constructed_variables=1000,\n",
    "    construction_rules=[\"TableMode\", \"TableSelection\"],\n",
    "    max_trees=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_predictor_mt_snowflake()`\n\n",
    "Trains a multi-table predictor for a dataset with a snowflake schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "accidents_dir = os.path.join(kh.get_samples_dir(), \"Accidents\")\n",
    "dictionary_file_path = os.path.join(accidents_dir, \"Accidents.kdic\")\n",
    "accidents_table_path = os.path.join(accidents_dir, \"Accidents.txt\")\n",
    "vehicles_table_path = os.path.join(accidents_dir, \"Vehicles.txt\")\n",
    "users_table_path = os.path.join(accidents_dir, \"Users.txt\")\n",
    "places_table_path = os.path.join(accidents_dir, \"Places.txt\")\n",
    "report_file_path = os.path.join(\n",
    "    \"kh_samples\", \"train_predictor_mt_snowflake\", \"AnalysisResults.khj\"\n",
    ")\n",
    "\n",
    "# Train the predictor. Besides the mandatory parameters, we specify:\n",
    "# - A python dictionary linking data paths to file paths for non-root tables\n",
    "# - To not construct any decision tree\n",
    "# The default number of automatic features is 100\n",
    "kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"Accident\",\n",
    "    accidents_table_path,\n",
    "    \"Gravity\",\n",
    "    report_file_path,\n",
    "    additional_data_tables={\n",
    "        \"Vehicles\": vehicles_table_path,\n",
    "        \"Vehicles/Users\": users_table_path,\n",
    "        \"Place\": places_table_path,\n",
    "    },\n",
    "    max_trees=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_predictor_with_train_percentage()`\n\n",
    "Trains a predictor with a 90%-10% train-test split\n\n    Note: The default is a 70%-30% split\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "dictionary_file_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.kdic\")\n",
    "data_table_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "report_file_path = os.path.join(\n",
    "    \"kh_samples\",\n",
    "    \"train_predictor_with_train_percentage\",\n",
    "    \"P90_AnalysisResults.khj\",\n",
    ")\n",
    "\n",
    "# Train the predictor. Besides the mandatory parameters, it is specified:\n",
    "# - A 90% sampling rate for the training dataset\n",
    "# - Set the test dataset as the complement of the training dataset (10%)\n",
    "# - No trees\n",
    "kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"Adult\",\n",
    "    data_table_path,\n",
    "    \"class\",\n",
    "    report_file_path,\n",
    "    sample_percentage=90,\n",
    "    use_complement_as_test=True,\n",
    "    max_trees=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_predictor_with_trees()`\n\n",
    "Trains a predictor based on 15 trees with a 80%-20% train-test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "dictionary_file_path = os.path.join(kh.get_samples_dir(), \"Letter\", \"Letter.kdic\")\n",
    "data_table_path = os.path.join(kh.get_samples_dir(), \"Letter\", \"Letter.txt\")\n",
    "report_file_path = os.path.join(\n",
    "    \"kh_samples\", \"train_predictor_with_trees\", \"P80_AnalysisResults.khj\"\n",
    ")\n",
    "\n",
    "# Train the predictor with at most 15 trees (default 10)\n",
    "kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"Letter\",\n",
    "    data_table_path,\n",
    "    \"lettr\",\n",
    "    report_file_path,\n",
    "    sample_percentage=80,\n",
    "    use_complement_as_test=True,\n",
    "    max_trees=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_predictor_with_pairs()`\n\n",
    "Trains a predictor with user specified pairs of variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "dictionary_file_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.kdic\")\n",
    "data_table_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "report_file_path = os.path.join(\n",
    "    \"kh_samples\", \"train_predictor_with_pairs\", \"AnalysisResults.khj\"\n",
    ")\n",
    "\n",
    "# Train the predictor with at most 10 pairs as follows:\n",
    "# - Include pairs age-race and capital_gain-capital_loss\n",
    "# - Include all possible pairs having relationship as component\n",
    "kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"Adult\",\n",
    "    data_table_path,\n",
    "    \"class\",\n",
    "    report_file_path,\n",
    "    use_complement_as_test=True,\n",
    "    max_trees=0,\n",
    "    max_pairs=10,\n",
    "    specific_pairs=[\n",
    "        (\"age\", \"race\"),\n",
    "        (\"capital_gain\", \"capital_loss\"),\n",
    "        (\"relationship\", \"\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_predictor_with_multiple_parameters()`\n\n",
    "Trains a predictor with various additional parameters\n\n    Some of these parameters are specific to `~.api.train_predictor` and others generic\n    to any Khiops execution.\n\n    In this example, we specify the following parameters in the call:\n     - A main target value\n     - The path where to store the \"Khiops scenario\" script\n     - The path where to store the log of the process\n     - The flag to show the execution trace (generic to any `khiops.core.api`\n       function)\n\n    Additionally the Khiops runner is set such that the learning is executed with only\n    1000 MB of memory.\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "dictionary_file_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.kdic\")\n",
    "data_table_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "output_dir = os.path.join(\"kh_samples\", \"train_predictor_with_multiple_parameters\")\n",
    "report_file_path = os.path.join(output_dir, \"AnalysisResults.khj\")\n",
    "output_script_path = os.path.join(output_dir, \"output_scenario._kh\")\n",
    "log_path = os.path.join(output_dir, \"log.txt\")\n",
    "\n",
    "# Train the predictor. Besides the mandatory parameters, we specify:\n",
    "# - The value \"more\" as main target value\n",
    "# - The output Khiops script file location (generic)\n",
    "# - The log file location (generic)\n",
    "# - The maximum memory used, set to 1000 MB\n",
    "# - To show the debug trace (generic)\n",
    "kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"Adult\",\n",
    "    data_table_path,\n",
    "    \"class\",\n",
    "    report_file_path,\n",
    "    main_target_value=\"more\",\n",
    "    output_scenario_path=output_script_path,\n",
    "    log_file_path=log_path,\n",
    "    memory_limit_mb=1000,\n",
    "    trace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_predictor_detect_format()`\n\n",
    "Trains a predictor without specifying the table format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "dictionary_file_path = os.path.join(kh.get_samples_dir(), \"Iris\", \"Iris.kdic\")\n",
    "data_table_path = os.path.join(kh.get_samples_dir(), \"Iris\", \"Iris.txt\")\n",
    "output_dir = os.path.join(\"kh_samples\", \"train_predictor_detect_format\")\n",
    "transformed_data_table_path = os.path.join(output_dir, \"TransformedIris.txt\")\n",
    "report_file_path = os.path.join(output_dir, \"AnalysisResults.khj\")\n",
    "\n",
    "# Transform the database format from header_line=True and field_separator=TAB\n",
    "# to header_line=False and field_separator=\",\"\n",
    "# See the deploy_model examples below for more details\n",
    "kh.deploy_model(\n",
    "    dictionary_file_path,\n",
    "    \"Iris\",\n",
    "    data_table_path,\n",
    "    transformed_data_table_path,\n",
    "    output_header_line=False,\n",
    "    output_field_separator=\",\",\n",
    ")\n",
    "\n",
    "# Try to learn with the old format\n",
    "try:\n",
    "    kh.train_predictor(\n",
    "        dictionary_file_path,\n",
    "        \"Iris\",\n",
    "        transformed_data_table_path,\n",
    "        \"Class\",\n",
    "        report_file_path,\n",
    "        header_line=True,\n",
    "        field_separator=\"\",\n",
    "    )\n",
    "except kh.KhiopsRuntimeError as error:\n",
    "    print(\n",
    "        \"This failed because of a bad data table format spec. \"\n",
    "        + \"Below the KhiopsRuntimeError message\"\n",
    "    )\n",
    "    print(error)\n",
    "\n",
    "# Train without specifyng the format (detect_format is True by default)\n",
    "kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"Iris\",\n",
    "    transformed_data_table_path,\n",
    "    \"Class\",\n",
    "    report_file_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_predictor_with_cross_validation()`\n\n",
    "Trains a predictor with a 5-fold cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import math\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "dictionary_file_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.kdic\")\n",
    "data_table_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "output_dir = os.path.join(\"kh_samples\", \"train_predictor_with_cross_validation\")\n",
    "fold_dictionary_file_path = os.path.join(output_dir, \"AdultWithFolding.kdic\")\n",
    "\n",
    "# Create the output directory\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "# Load the learning dictionary object\n",
    "domain = kh.read_dictionary_file(dictionary_file_path)\n",
    "dictionary = domain.get_dictionary(\"Adult\")\n",
    "\n",
    "# Add a random fold index variable to the learning dictionary\n",
    "fold_number = 5\n",
    "fold_index_variable = kh.Variable()\n",
    "fold_index_variable.name = \"FoldIndex\"\n",
    "fold_index_variable.type = \"Numerical\"\n",
    "fold_index_variable.used = False\n",
    "fold_index_variable.rule = \"Ceil(Product(\" + str(fold_number) + \",  Random()))\"\n",
    "dictionary.add_variable(fold_index_variable)\n",
    "\n",
    "# Add variables that indicate if the instance is in the train dataset:\n",
    "for fold_index in range(1, fold_number + 1):\n",
    "    is_in_train_dataset_variable = kh.Variable()\n",
    "    is_in_train_dataset_variable.name = \"IsInTrainDataset\" + str(fold_index)\n",
    "    is_in_train_dataset_variable.type = \"Numerical\"\n",
    "    is_in_train_dataset_variable.used = False\n",
    "    is_in_train_dataset_variable.rule = \"NEQ(FoldIndex, \" + str(fold_index) + \")\"\n",
    "    dictionary.add_variable(is_in_train_dataset_variable)\n",
    "\n",
    "# Print dictionary with fold variables\n",
    "print(\"Dictionary file with fold variables\")\n",
    "domain.export_khiops_dictionary_file(fold_dictionary_file_path)\n",
    "with open(fold_dictionary_file_path) as fold_dictionary_file:\n",
    "    for line in fold_dictionary_file:\n",
    "        print(line, end=\"\")\n",
    "\n",
    "# For each fold k:\n",
    "print(\"Training Adult with \" + str(fold_number) + \" folds\")\n",
    "print(\"\\tfold\\ttrain auc\\ttest auc\")\n",
    "train_aucs = []\n",
    "test_aucs = []\n",
    "for fold_index in range(1, fold_number + 1):\n",
    "    analysis_report_file_path = os.path.join(\n",
    "        output_dir, \"Fold\" + str(fold_index) + \"AnalysisResults.khj\"\n",
    "    )\n",
    "    # Train a model from the sub-dataset where IsInTrainDataset<k> is 1\n",
    "    _, modeling_dictionary_file_path = kh.train_predictor(\n",
    "        domain,\n",
    "        \"Adult\",\n",
    "        data_table_path,\n",
    "        \"class\",\n",
    "        analysis_report_file_path,\n",
    "        sample_percentage=100,\n",
    "        selection_variable=\"IsInTrainDataset\" + str(fold_index),\n",
    "        selection_value=1,\n",
    "        max_trees=0,\n",
    "    )\n",
    "\n",
    "    evaluation_report_file_path = os.path.join(\n",
    "        output_dir, \"Fold\" + str(fold_index) + \"AdultEvaluationResults.khj\"\n",
    "    )\n",
    "    # Evaluate the resulting model in the subsets where IsInTrainDataset is 0\n",
    "    test_evaluation_report_path = kh.evaluate_predictor(\n",
    "        modeling_dictionary_file_path,\n",
    "        \"SNB_Adult\",\n",
    "        data_table_path,\n",
    "        evaluation_report_file_path,\n",
    "        sample_percentage=100,\n",
    "        selection_variable=\"IsInTrainDataset\" + str(fold_index),\n",
    "        selection_value=0,\n",
    "    )\n",
    "\n",
    "    # Obtain the train AUC from the train report and the test AUC from the\n",
    "    # evaluation report and print them\n",
    "    train_results = kh.read_analysis_results_file(analysis_report_file_path)\n",
    "    test_evaluation_results = kh.read_analysis_results_file(test_evaluation_report_path)\n",
    "    train_auc = train_results.train_evaluation_report.get_snb_performance().auc\n",
    "    test_auc = test_evaluation_results.evaluation_report.get_snb_performance().auc\n",
    "    print(\"\\t\" + str(fold_index) + \"\\t\" + str(train_auc) + \"\\t\" + str(test_auc))\n",
    "\n",
    "    # Store the train and test AUCs in arrays\n",
    "    train_aucs.append(train_auc)\n",
    "    test_aucs.append(test_auc)\n",
    "\n",
    "# Print the mean +- error aucs for both train and test\n",
    "mean_train_auc = sum(train_aucs) / fold_number\n",
    "squared_error_train_aucs = [(auc - mean_train_auc) ** 2 for auc in train_aucs]\n",
    "sd_train_auc = math.sqrt(sum(squared_error_train_aucs) / (fold_number - 1))\n",
    "\n",
    "mean_test_auc = sum(test_aucs) / fold_number\n",
    "squared_error_test_aucs = [(auc - mean_test_auc) ** 2 for auc in test_aucs]\n",
    "sd_test_auc = math.sqrt(sum(squared_error_test_aucs) / (fold_number - 1))\n",
    "\n",
    "print(\"final auc\")\n",
    "print(\"train auc: \" + str(mean_train_auc) + \" +- \" + str(sd_train_auc))\n",
    "print(\"test  auc: \" + str(mean_test_auc) + \" +- \" + str(sd_test_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `interpret_predictor()`\n\n",
    "Builds interpretation model for existing predictor\n\n    It calls `~.api.train_predictor` and `~.api.interpret_predictor` only with\n    their mandatory parameters.\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "dictionary_file_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.kdic\")\n",
    "data_table_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "output_dir = os.path.join(\"kh_samples\", \"interpret_predictor\")\n",
    "analysis_report_file_path = os.path.join(output_dir, \"AnalysisResults.khj\")\n",
    "interpretor_file_path = os.path.join(output_dir, \"InterpretationModel.kdic\")\n",
    "\n",
    "# Build prediction model\n",
    "_, predictor_file_path = kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"Adult\",\n",
    "    data_table_path,\n",
    "    \"class\",\n",
    "    analysis_report_file_path,\n",
    ")\n",
    "\n",
    "# Build interpretation model\n",
    "kh.interpret_predictor(predictor_file_path, \"SNB_Adult\", interpretor_file_path)\n",
    "\n",
    "print(f\"The interpretation model is '{interpretor_file_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `multiple_train_predictor()`\n\n",
    "Trains a sequence of models with a decreasing number of variables\n\n    This example illustrates the use of the khiops classes `.DictionaryDomain` (for\n    reading dictionary files) and `.AnalysisResults` (for reading training/evaluation\n    results from JSON)\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "\n",
    "def display_test_results(json_result_file_path):\n",
    "    \"\"\"Display some of the training results\"\"\"\n",
    "    results = kh.read_analysis_results_file(json_result_file_path)\n",
    "    train_performance = results.train_evaluation_report.get_snb_performance()\n",
    "    test_performance = results.test_evaluation_report.get_snb_performance()\n",
    "    print(\n",
    "        \"\\t\"\n",
    "        + str(len(results.preparation_report.variables_statistics))\n",
    "        + \"\\t\"\n",
    "        + str(train_performance.auc)\n",
    "        + \"\\t\"\n",
    "        + str(test_performance.auc)\n",
    "    )\n",
    "\n",
    "\n",
    "# Set the file paths\n",
    "dictionary_file_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.kdic\")\n",
    "data_table_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "output_dir = os.path.join(\"kh_samples\", \"multiple_train_predictor\")\n",
    "report_file_path = os.path.join(output_dir, \"AnalysisResults.khj\")\n",
    "\n",
    "# Read the dictionary file to obtain an instance of class Dictionary\n",
    "dictionary_domain = kh.read_dictionary_file(dictionary_file_path)\n",
    "dictionary = dictionary_domain.get_dictionary(\"Adult\")\n",
    "\n",
    "# Train a SNB model using all the variables\n",
    "print(\"\\t#vars\\ttrain auc\\ttest auc\")\n",
    "kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"Adult\",\n",
    "    data_table_path,\n",
    "    \"class\",\n",
    "    report_file_path,\n",
    "    sample_percentage=70,\n",
    "    use_complement_as_test=True,\n",
    "    max_trees=0,\n",
    ")\n",
    "display_test_results(report_file_path)\n",
    "\n",
    "# Read results to obtain the variables sorted by decreasing Level\n",
    "analysis_results = kh.read_analysis_results_file(report_file_path)\n",
    "preparation_results = analysis_results.preparation_report\n",
    "\n",
    "# Train a sequence of models with a decreasing number of variables\n",
    "# We disable variables one-by-one in increasing level (predictive power) order\n",
    "variable_number = len(preparation_results.variables_statistics)\n",
    "for i in reversed(range(variable_number)):\n",
    "    # Search the next variable\n",
    "    variable = preparation_results.variables_statistics[i]\n",
    "\n",
    "    # Disable this variable and save the dictionary with the Khiops format\n",
    "    dictionary.get_variable(variable.name).used = False\n",
    "\n",
    "    # Train the model with this dictionary domain object\n",
    "    report_file_path = os.path.join(\n",
    "        output_dir, f\"V{variable_number - 1 - i}_AnalysisResults.khj\"\n",
    "    )\n",
    "    kh.train_predictor(\n",
    "        dictionary_domain,\n",
    "        \"Adult\",\n",
    "        data_table_path,\n",
    "        \"class\",\n",
    "        report_file_path,\n",
    "        sample_percentage=70,\n",
    "        use_complement_as_test=True,\n",
    "        max_trees=0,\n",
    "    )\n",
    "\n",
    "    # Show a preview of the results\n",
    "    display_test_results(report_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `evaluate_predictor()`\n\n",
    "Evaluates a predictor in the simplest way possible\n\n    It calls `~.api.evaluate_predictor` with only its mandatory parameters.\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "dictionary_file_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.kdic\")\n",
    "data_table_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "output_dir = os.path.join(\"kh_samples\", \"evaluate_predictor\")\n",
    "analysis_report_file_path = os.path.join(output_dir, \"AnalysisResults.khj\")\n",
    "\n",
    "# Train the predictor\n",
    "_, model_dictionary_file_path = kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"Adult\",\n",
    "    data_table_path,\n",
    "    \"class\",\n",
    "    analysis_report_file_path,\n",
    "    max_trees=0,\n",
    ")\n",
    "\n",
    "evaluation_report_file_path = os.path.join(output_dir, \"AdultEvaluationResults.khj\")\n",
    "\n",
    "# Evaluate the predictor\n",
    "kh.evaluate_predictor(\n",
    "    model_dictionary_file_path,\n",
    "    \"SNB_Adult\",\n",
    "    data_table_path,\n",
    "    evaluation_report_file_path,\n",
    ")\n",
    "print(\"Evaluation report available at \" + evaluation_report_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `access_predictor_evaluation_report()`\n\n",
    "Shows the performance metrics of a predictor\n\n    See `evaluate_predictor` or `train_predictor_with_train_percentage` to see examples\n    on how to evaluate a model.\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "dictionary_file_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.kdic\")\n",
    "data_table_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "report_file_path = os.path.join(\n",
    "    \"kh_samples\", \"access_predictor_evaluation_report\", \"AdultAnalysisReport.khj\"\n",
    ")\n",
    "\n",
    "# Train the SNB predictor and some univariate predictors\n",
    "# Note: Evaluation in test is 30% by default\n",
    "kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"Adult\",\n",
    "    data_table_path,\n",
    "    \"class\",\n",
    "    report_file_path,\n",
    "    max_trees=0,\n",
    ")\n",
    "\n",
    "# Obtain the evaluation results\n",
    "results = kh.read_analysis_results_file(report_file_path)\n",
    "evaluation_report = results.test_evaluation_report\n",
    "snb_performance = evaluation_report.get_snb_performance()\n",
    "\n",
    "# Print univariate metrics for the SNB\n",
    "print(\"\\nperformance metrics for \" + snb_performance.name)\n",
    "for metric_name in snb_performance.get_metric_names():\n",
    "    print(metric_name + \": \" + str(snb_performance.get_metric(metric_name)))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"\\nconfusion matrix:\")\n",
    "confusion_matrix = snb_performance.confusion_matrix\n",
    "\n",
    "for target_value in confusion_matrix.values:\n",
    "    print(\"\\t\" + target_value, end=\"\")\n",
    "print(\"\")\n",
    "\n",
    "for i, target_value in enumerate(confusion_matrix.values):\n",
    "    observed_frequencies = confusion_matrix.matrix[i]\n",
    "    print(target_value, end=\"\")\n",
    "    for frequency in observed_frequencies:\n",
    "        print(\"\\t\" + str(frequency), end=\"\")\n",
    "    print(\"\")\n",
    "\n",
    "# Print the head of the lift curves for the 'more' modality\n",
    "print(\"\\nfirst five values of the lift curves for 'more'\")\n",
    "\n",
    "snb_lift_curve = evaluation_report.get_snb_lift_curve(\"more\")\n",
    "optimal_lift_curve = evaluation_report.get_classifier_lift_curve(\"Optimal\", \"more\")\n",
    "random_lift_curve = evaluation_report.get_classifier_lift_curve(\"Random\", \"more\")\n",
    "\n",
    "for i in range(5):\n",
    "    print(\n",
    "        str(snb_lift_curve.values[i])\n",
    "        + \"\\t\"\n",
    "        + str(optimal_lift_curve.values[i])\n",
    "        + \"\\t\"\n",
    "        + str(random_lift_curve.values[i])\n",
    "    )\n",
    "\n",
    "# Print metrics for an SNB predictor\n",
    "predictor_performance = evaluation_report.get_predictor_performance(\n",
    "    \"Selective Naive Bayes\"\n",
    ")\n",
    "print(\"\\n\\nperformance metrics for \" + predictor_performance.name)\n",
    "for metric_name in predictor_performance.get_metric_names():\n",
    "    print(metric_name + \": \" + str(predictor_performance.get_metric(metric_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_recoder()`\n\n",
    "Train a database recoder in the simplest way possible\n\n    It is a call to `~.api.train_recoder` with only its mandatory parameters.\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "dictionary_file_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.kdic\")\n",
    "data_table_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "report_file_path = os.path.join(\"kh_samples\", \"train_recoder\", \"AnalysisResults.khj\")\n",
    "\n",
    "# Train the recoder model\n",
    "kh.train_recoder(\n",
    "    dictionary_file_path, \"Adult\", data_table_path, \"class\", report_file_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_recoder_with_multiple_parameters()`\n\n",
    "Trains a recoder that transforms variable values to their respective part labels\n\n    It also creates 10 pair features.\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "dictionary_file_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.kdic\")\n",
    "data_table_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "report_file_path = os.path.join(\n",
    "    \"kh_samples\",\n",
    "    \"train_recoder_with_multiple_parameters\",\n",
    "    \"AnalysisResults.khj\",\n",
    ")\n",
    "\n",
    "# Train the recoder model\n",
    "kh.train_recoder(\n",
    "    dictionary_file_path,\n",
    "    \"Adult\",\n",
    "    data_table_path,\n",
    "    \"class\",\n",
    "    report_file_path,\n",
    "    max_pairs=10,\n",
    "    categorical_recoding_method=\"part label\",\n",
    "    numerical_recoding_method=\"part label\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_recoder_mt_flatten()`\n\n",
    "Trains a recoder that flattens a multi-table database into a single table\n\n    The constructed variables are all kept and no recoding is performed on their values\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "accidents_dir = os.path.join(kh.get_samples_dir(), \"AccidentsSummary\")\n",
    "dictionary_file_path = os.path.join(accidents_dir, \"Accidents.kdic\")\n",
    "accidents_table_path = os.path.join(accidents_dir, \"Accidents.txt\")\n",
    "vehicles_table_path = os.path.join(accidents_dir, \"Vehicles.txt\")\n",
    "report_file_path = os.path.join(\n",
    "    \"kh_samples\", \"train_recoder_mt_flatten\", \"AnalysisResults.khj\"\n",
    ")\n",
    "\n",
    "# Train the recoder. Besides the mandatory parameters, it is specified:\n",
    "# - A python dictionary linking data paths to file paths for non-root tables\n",
    "# - The maximum number of aggregate variables to construct (1000)\n",
    "# - To keep all the created variables independently of their informativeness (level)\n",
    "# - To not recode the variables values\n",
    "kh.train_recoder(\n",
    "    dictionary_file_path,\n",
    "    \"Accident\",\n",
    "    accidents_table_path,\n",
    "    \"Gravity\",\n",
    "    report_file_path,\n",
    "    additional_data_tables={\"Vehicles\": vehicles_table_path},\n",
    "    max_constructed_variables=1000,\n",
    "    informative_variables_only=False,\n",
    "    categorical_recoding_method=\"none\",\n",
    "    numerical_recoding_method=\"none\",\n",
    "    keep_initial_categorical_variables=True,\n",
    "    keep_initial_numerical_variables=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `deploy_model()`\n\n",
    "Deploys a model in the simplest way possible\n\n    It is a call to `~.api.deploy_model` with its mandatory parameters.\n\n    In this example, a Selective Naive Bayes (SNB) model is deployed by applying its\n    associated dictionary to the input database. The model predictions are written to\n    the output database.\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "dictionary_file_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.kdic\")\n",
    "data_table_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "output_dir = os.path.join(\"kh_samples\", \"deploy_model\")\n",
    "report_file_path = os.path.join(output_dir, \"AnalysisResults.khj\")\n",
    "output_data_table_path = os.path.join(output_dir, \"ScoresAdult.txt\")\n",
    "\n",
    "# Train the predictor\n",
    "_, model_dictionary_file_path = kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"Adult\",\n",
    "    data_table_path,\n",
    "    \"class\",\n",
    "    report_file_path,\n",
    "    max_trees=0,\n",
    ")\n",
    "\n",
    "# Deploy the model on the database\n",
    "# It will score it according to the trained predictor\n",
    "kh.deploy_model(\n",
    "    model_dictionary_file_path, \"SNB_Adult\", data_table_path, output_data_table_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `deploy_model_text()`\n\n",
    "Deploys a model learned on textual data\n    It is a call to `~.api.deploy_model` with its mandatory parameters, plus\n    text-specific parameters.\n\n    In this example, a Selective Naive Bayes (SNB) model is deployed by applying its\n    associated dictionary to the input database. The model predictions are written to\n    the output database.\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "dictionary_file_path = os.path.join(\n",
    "    kh.get_samples_dir(), \"NegativeAirlineTweets\", \"NegativeAirlineTweets.kdic\"\n",
    ")\n",
    "data_table_path = os.path.join(\n",
    "    kh.get_samples_dir(), \"NegativeAirlineTweets\", \"NegativeAirlineTweets.txt\"\n",
    ")\n",
    "output_dir = os.path.join(\"kh_samples\", \"deploy_model_text\")\n",
    "report_file_path = os.path.join(output_dir, \"AnalysisResults.khj\")\n",
    "output_data_table_path = os.path.join(output_dir, \"ScoresNegativeAirlineTweets.txt\")\n",
    "\n",
    "# Train the predictor\n",
    "_, model_dictionary_file_path = kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"FlightNegativeTweets\",\n",
    "    data_table_path,\n",
    "    \"negativereason\",\n",
    "    report_file_path,\n",
    "    max_trees=5,\n",
    "    max_text_features=1000,\n",
    "    text_features=\"words\",\n",
    ")\n",
    "\n",
    "# Deploy the model on the database\n",
    "# It will score it according to the trained predictor\n",
    "kh.deploy_model(\n",
    "    model_dictionary_file_path,\n",
    "    \"SNB_FlightNegativeTweets\",\n",
    "    data_table_path,\n",
    "    output_data_table_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `deploy_model_mt()`\n\n",
    "Deploys a multi-table classifier in the simplest way possible\n\n    It is a call to `~.api.deploy_model` with additional parameters to handle\n    multi-table deployment.\n\n    In this example, a Selective Naive Bayes (SNB) model is deployed by applying its\n    associated dictionary to the input database. The model predictions are written to\n    the output database.\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "accidents_dir = os.path.join(kh.get_samples_dir(), \"AccidentsSummary\")\n",
    "dictionary_file_path = os.path.join(accidents_dir, \"Accidents.kdic\")\n",
    "accidents_table_path = os.path.join(accidents_dir, \"Accidents.txt\")\n",
    "vehicles_table_path = os.path.join(accidents_dir, \"Vehicles.txt\")\n",
    "output_dir = os.path.join(\"kh_samples\", \"deploy_model_mt\")\n",
    "report_file_path = os.path.join(output_dir, \"AnalysisResults.khj\")\n",
    "output_data_table_path = os.path.join(output_dir, \"TransferredAccidents.txt\")\n",
    "\n",
    "# Train the predictor (see train_predictor_mt for details)\n",
    "_, model_dictionary_file_path = kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"Accident\",\n",
    "    accidents_table_path,\n",
    "    \"Gravity\",\n",
    "    report_file_path,\n",
    "    additional_data_tables={\"Vehicles\": vehicles_table_path},\n",
    "    max_trees=0,\n",
    ")\n",
    "\n",
    "# Deploy the model on the database\n",
    "# Besides the mandatory parameters, it is specified:\n",
    "# - A python dictionary linking data paths to file paths for non-root tables\n",
    "kh.deploy_model(\n",
    "    model_dictionary_file_path,\n",
    "    \"SNB_Accident\",\n",
    "    accidents_table_path,\n",
    "    output_data_table_path,\n",
    "    additional_data_tables={\"Vehicles\": vehicles_table_path},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `deploy_model_mt_with_interpretation()`\n\n",
    "Deploys a multi-table interpretor in the simplest way possible\n\n    It is a call to `~.api.deploy_model` with additional parameters to handle\n    multi-table deployment.\n\n    In this example, a Selective Naive Bayes (SNB) interpretation model is\n    deployed by applying its associated dictionary to the input database.\n    The model variable importances are written to the output data table.\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "accidents_dir = os.path.join(kh.get_samples_dir(), \"AccidentsSummary\")\n",
    "dictionary_file_path = os.path.join(accidents_dir, \"Accidents.kdic\")\n",
    "accidents_table_path = os.path.join(accidents_dir, \"Accidents.txt\")\n",
    "vehicles_table_path = os.path.join(accidents_dir, \"Vehicles.txt\")\n",
    "output_dir = os.path.join(\"kh_samples\", \"deploy_model_mt\")\n",
    "report_file_path = os.path.join(output_dir, \"AnalysisResults.khj\")\n",
    "interpretor_file_path = os.path.join(output_dir, \"InterpretationModel.kdic\")\n",
    "output_data_table_path = os.path.join(output_dir, \"InterpretedAccidents.txt\")\n",
    "\n",
    "# Train the predictor (see train_predictor_mt for details)\n",
    "# Add max_evaluated_variables so that an interpretation model can be built\n",
    "# (see https://github.com/KhiopsML/khiops/issues/577)\n",
    "_, model_dictionary_file_path = kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"Accident\",\n",
    "    accidents_table_path,\n",
    "    \"Gravity\",\n",
    "    report_file_path,\n",
    "    additional_data_tables={\"Vehicles\": vehicles_table_path},\n",
    "    max_trees=0,\n",
    "    max_evaluated_variables=10,\n",
    ")\n",
    "\n",
    "# Interpret the predictor\n",
    "kh.interpret_predictor(\n",
    "    model_dictionary_file_path,\n",
    "    \"SNB_Accident\",\n",
    "    interpretor_file_path,\n",
    "    reinforcement_target_value=\"NonLethal\",\n",
    ")\n",
    "\n",
    "# Deploy the interpretation model on the database\n",
    "# Besides the mandatory parameters, it is specified:\n",
    "# - A python dictionary linking data paths to file paths for non-root tables\n",
    "kh.deploy_model(\n",
    "    interpretor_file_path,\n",
    "    \"Interpretation_SNB_Accident\",\n",
    "    accidents_table_path,\n",
    "    output_data_table_path,\n",
    "    additional_data_tables={\"Vehicles\": vehicles_table_path},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `deploy_model_mt_snowflake()`\n\n",
    "Deploys a classifier model on a dataset with a snowflake schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "accidents_dir = os.path.join(kh.get_samples_dir(), \"Accidents\")\n",
    "dictionary_file_path = os.path.join(accidents_dir, \"Accidents.kdic\")\n",
    "accidents_table_path = os.path.join(accidents_dir, \"Accidents.txt\")\n",
    "vehicles_table_path = os.path.join(accidents_dir, \"Vehicles.txt\")\n",
    "users_table_path = os.path.join(accidents_dir, \"Users.txt\")\n",
    "places_table_path = os.path.join(accidents_dir, \"Places.txt\")\n",
    "output_dir = os.path.join(\"kh_samples\", \"deploy_model_mt_snowflake\")\n",
    "report_file_path = os.path.join(output_dir, \"AnalysisResults.khj\")\n",
    "output_data_table_path = os.path.join(output_dir, \"TransferredAccidents.txt\")\n",
    "\n",
    "# Train the predictor. Besides the mandatory parameters, we specify:\n",
    "# - A python dictionary linking data paths to file paths for non-root tables\n",
    "# - To not construct any decision tree\n",
    "# The default number of automatic features is 100\n",
    "_, model_dictionary_file_path = kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"Accident\",\n",
    "    accidents_table_path,\n",
    "    \"Gravity\",\n",
    "    report_file_path,\n",
    "    additional_data_tables={\n",
    "        \"Vehicles\": vehicles_table_path,\n",
    "        \"Vehicles/Users\": users_table_path,\n",
    "        \"Place\": places_table_path,\n",
    "    },\n",
    "    max_trees=0,\n",
    ")\n",
    "\n",
    "# Deploy the model on the database\n",
    "# Besides the mandatory parameters, it is specified:\n",
    "# - A python dictionary linking data paths to file paths for non-root tables\n",
    "kh.deploy_model(\n",
    "    model_dictionary_file_path,\n",
    "    \"SNB_Accident\",\n",
    "    accidents_table_path,\n",
    "    output_data_table_path,\n",
    "    additional_data_tables={\n",
    "        \"Vehicles\": vehicles_table_path,\n",
    "        \"Vehicles/Users\": users_table_path,\n",
    "        \"Place\": places_table_path,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `deploy_model_expert()`\n\n",
    "Deploys a model with a specification of additional variables to be included\n\n    In this example, a Selective Naive Bayes (SNB) model is deployed by applying its\n    associated dictionary to the input database. Specifically, the output file contains:\n\n    - The model predictions\n    - The probabilities of all modalities of the target variable.\n\n    The \"expert\" part of this example is the use of the khiops dictionary interface\n    and the `.DictionaryDomain` class\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "dictionary_file_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.kdic\")\n",
    "data_table_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "output_dir = os.path.join(\"kh_samples\", \"deploy_model_expert\")\n",
    "report_file_path = os.path.join(output_dir, \"AnalysisResults.khj\")\n",
    "output_data_table_path = os.path.join(output_dir, \"ScoresAdult.txt\")\n",
    "\n",
    "# Train the predictor\n",
    "_, model_dictionary_file_path = kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"Adult\",\n",
    "    data_table_path,\n",
    "    \"class\",\n",
    "    report_file_path,\n",
    "    max_trees=0,\n",
    ")\n",
    "\n",
    "# Read the dictionary file to obtain an instance of class Dictionary\n",
    "model_domain = kh.read_dictionary_file(model_dictionary_file_path)\n",
    "snb_dictionary = model_domain.get_dictionary(\"SNB_Adult\")\n",
    "\n",
    "# Select Label (identifier)\n",
    "snb_dictionary.get_variable(\"Label\").used = True\n",
    "\n",
    "# Select the variables containing the probabilities for each class\n",
    "for variable in snb_dictionary.variables:\n",
    "    # The variable must have a meta data with key that start with \"target_prob\"\n",
    "    for key in variable.meta_data.keys:\n",
    "        if key.startswith(\"TargetProb\"):\n",
    "            variable.used = True\n",
    "\n",
    "# Deploy the model. Besides the mandatory parameters, it is specified:\n",
    "# - A DictionaryDomain object to use instead of the mandatory dictionary file\n",
    "kh.deploy_model(model_domain, \"SNB_Adult\", data_table_path, output_data_table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `deploy_classifier_for_metrics()`\n\n",
    "Constructs a small precision-recall curve for a classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "dictionary_file_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.kdic\")\n",
    "data_table_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "output_dir = os.path.join(\"kh_samples\", \"deploy_classifier_for_metrics\")\n",
    "report_file_path = os.path.join(output_dir, \"AnalysisResults.khj\")\n",
    "output_data_table_path = os.path.join(output_dir, \"ScoresAdult.txt\")\n",
    "\n",
    "# Train the classifier for the target \"class\"\n",
    "_, modeling_dictionary_file_path = kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"Adult\",\n",
    "    data_table_path,\n",
    "    \"class\",\n",
    "    report_file_path,\n",
    "    max_trees=0,\n",
    ")\n",
    "# Obtain the scores of the SNB on the test dataset to calculate the PR curve\n",
    "kh.deploy_predictor_for_metrics(\n",
    "    modeling_dictionary_file_path,\n",
    "    \"SNB_Adult\",\n",
    "    data_table_path,\n",
    "    output_data_table_path,\n",
    "    sampling_mode=\"Exclude sample\",\n",
    "    output_header_line=False,\n",
    ")\n",
    "\n",
    "# We estimate the precision/recall for the class \"more\" and increasing thresholds\n",
    "# Note: Normally one would do this with a package (eg. sklearn.metrics)\n",
    "thresholds = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "true_positives = {thres: 0 for thres in thresholds}\n",
    "false_positives = {thres: 0 for thres in thresholds}\n",
    "false_negatives = {thres: 0 for thres in thresholds}\n",
    "with open(output_data_table_path) as output_data_table:\n",
    "    for line in output_data_table:\n",
    "        fields = line.split(\"\\t\")\n",
    "        true_target = fields[0]\n",
    "        proba_more = float(fields[3])\n",
    "        for thres in thresholds:\n",
    "            if true_target == \"more\" and proba_more >= thres:\n",
    "                true_positives[thres] += 1\n",
    "            elif true_target == \"more\" and proba_more < thres:\n",
    "                false_negatives[thres] += 1\n",
    "            elif true_target == \"less\" and proba_more >= thres:\n",
    "                false_positives[thres] += 1\n",
    "\n",
    "precision = {\n",
    "    thres: true_positives[thres] / (true_positives[thres] + false_positives[thres])\n",
    "    for thres in thresholds\n",
    "}\n",
    "recall = {\n",
    "    thres: true_positives[thres] / (true_positives[thres] + false_negatives[thres])\n",
    "    for thres in thresholds\n",
    "}\n",
    "\n",
    "# Print the curve at the selected points\n",
    "print(\"Precision and Recall for class 'more'\")\n",
    "print(\"threshold\\trecall\\tprecision\")\n",
    "thresholds.reverse()\n",
    "for thres in thresholds:\n",
    "    print(str(thres) + \"\\t\" + str(recall[thres]) + \"\\t\" + str(precision[thres]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `deploy_regressor_for_metrics()`\n\n",
    "Estimates the R2 coefficient of a regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "dictionary_file_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.kdic\")\n",
    "data_table_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "output_dir = os.path.join(\"kh_samples\", \"deploy_regressor_for_metrics\")\n",
    "report_file_path = os.path.join(output_dir, \"AnalysisResults.khj\")\n",
    "output_data_table_path = os.path.join(output_dir, \"TrueAndPredictedAges.txt\")\n",
    "\n",
    "# Train the regressor for the target \"age\" (with 20% train to be quick)\n",
    "_, modeling_dictionary_file_path = kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"Adult\",\n",
    "    data_table_path,\n",
    "    \"age\",\n",
    "    report_file_path,\n",
    "    sample_percentage=20,\n",
    "    max_trees=0,\n",
    ")\n",
    "\n",
    "# Obtain the predicted regression values of the SNB on the test dataset estimate R2\n",
    "kh.deploy_predictor_for_metrics(\n",
    "    modeling_dictionary_file_path,\n",
    "    \"SNB_Adult\",\n",
    "    data_table_path,\n",
    "    output_data_table_path,\n",
    "    sample_percentage=20,\n",
    "    sampling_mode=\"Exclude sample\",\n",
    "    output_header_line=False,\n",
    ")\n",
    "# Estimate R2\n",
    "# Note: Normally one would do this with a package (eg. sklearn.metrics)\n",
    "# First pass to estimate sums of residuals and the mean\n",
    "ss_res = 0\n",
    "mean = 0\n",
    "n_instances = 0\n",
    "with open(output_data_table_path) as output_data_table:\n",
    "    for line in output_data_table:\n",
    "        fields = line.split(\"\\t\")\n",
    "        true_target = float(fields[0])\n",
    "        predicted_target = float(fields[1])\n",
    "        ss_res += (true_target - predicted_target) ** 2\n",
    "        mean += true_target\n",
    "        n_instances += 1\n",
    "    mean /= n_instances\n",
    "\n",
    "# Second pass to estimate the total sums of squares and finish the R2 estimation\n",
    "ss_tot = 0\n",
    "with open(output_data_table_path) as output_data_table:\n",
    "    for line in output_data_table:\n",
    "        fields = line.split(\"\\t\")\n",
    "        true_target = float(fields[0])\n",
    "        ss_tot += (true_target - mean) ** 2\n",
    "r2_score = 1 - ss_res / ss_tot\n",
    "\n",
    "# Print results\n",
    "print(\"Adult 'age' regression (30% train)\")\n",
    "print(f\"R2 (explained variance) = {r2_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sort_data_table()`\n\n",
    "Sorts a database in the simplest way possible\n\n    It is a call to `~.api.sort_data_table` with only its mandatory parameters. This\n    sorts a data table by its default key variable (specified in the table's\n    dictionary).\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "accidents_dir = os.path.join(kh.get_samples_dir(), \"AccidentsSummary\")\n",
    "dictionary_file_path = os.path.join(accidents_dir, \"Accidents.kdic\")\n",
    "accidents_table_path = os.path.join(accidents_dir, \"Accidents.txt\")\n",
    "output_data_table_path = os.path.join(\n",
    "    \"kh_samples\",\n",
    "    \"sort_data_table\",\n",
    "    \"SortedAccidents.txt\",\n",
    ")\n",
    "\n",
    "# Sort table\n",
    "kh.sort_data_table(\n",
    "    dictionary_file_path, \"Accident\", accidents_table_path, output_data_table_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sort_data_table_expert()`\n\n",
    "Sorts a database by a field other than the default table key\n\n    It is a call to `~.api.sort_data_table` with additional parameters to specify the\n    sorting fields.\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "accidents_dir = os.path.join(kh.get_samples_dir(), \"AccidentsSummary\")\n",
    "dictionary_file_path = os.path.join(accidents_dir, \"Accidents.kdic\")\n",
    "vehicles_table_path = os.path.join(accidents_dir, \"Vehicles.txt\")\n",
    "output_data_table_path = os.path.join(\n",
    "    \"kh_samples\", \"sort_data_table_expert\", \"SortedVehicles.txt\"\n",
    ")\n",
    "\n",
    "# Sort table. Besides the mandatory parameters, it is specified:\n",
    "# - A list containing the sorting fields\n",
    "kh.sort_data_table(\n",
    "    dictionary_file_path,\n",
    "    \"Vehicle\",\n",
    "    vehicles_table_path,\n",
    "    output_data_table_path,\n",
    "    sort_variables=[\"AccidentId\", \"VehicleId\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `extract_keys_from_data_table()`\n\n",
    "Extracts the keys from a database\n\n    It is a call to `~.api.extract_keys_from_data_table` with only its mandatory\n    parameters.\n\n    Pre-requisite: the database must be sorted by its key.\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "splice_dir = os.path.join(kh.get_samples_dir(), \"SpliceJunction\")\n",
    "dictionary_file_path = os.path.join(splice_dir, \"SpliceJunction.kdic\")\n",
    "data_table_path = os.path.join(splice_dir, \"SpliceJunctionDNA.txt\")\n",
    "output_data_table_path = os.path.join(\n",
    "    \"kh_samples\",\n",
    "    \"extract_keys_from_data_table\",\n",
    "    \"KeysSpliceJunction.txt\",\n",
    ")\n",
    "\n",
    "# Extract keys from table \"SpliceJunctionDNA\" to the output table\n",
    "kh.extract_keys_from_data_table(\n",
    "    dictionary_file_path,\n",
    "    \"SpliceJunctionDNA\",\n",
    "    data_table_path,\n",
    "    output_data_table_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_coclustering()`\n\n",
    "Trains a coclustering model in the simplest way possible\n\n    It is a call to `~.api.train_coclustering` with only its mandatory parameters.\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "splice_dir = os.path.join(kh.get_samples_dir(), \"SpliceJunction\")\n",
    "dictionary_file_path = os.path.join(splice_dir, \"SpliceJunction.kdic\")\n",
    "data_table_path = os.path.join(splice_dir, \"SpliceJunctionDNA.txt\")\n",
    "coclustering_report_path = os.path.join(\n",
    "    \"kh_samples\", \"train_coclustering\", \"CoclusteringResults.khcj\"\n",
    ")\n",
    "\n",
    "# Train a coclustering model for variables \"SampleId\" and \"Char\"\n",
    "kh.train_coclustering(\n",
    "    dictionary_file_path,\n",
    "    \"SpliceJunctionDNA\",\n",
    "    data_table_path,\n",
    "    [\"SampleId\", \"Char\"],\n",
    "    coclustering_report_path,\n",
    ")\n",
    "print(f\"Coclustering report file available at {coclustering_report_path}\")\n",
    "\n",
    "# If you have Khiops Co-Visualization installed you may open the report as follows\n",
    "# kh.visualize_report(coclustering_report_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_instance_variable_coclustering()`\n\n",
    "Trains an instance-variable coclustering model in the simplest way possible\n\n    It is a call to `~.api.train_instance_variable_coclustering` with only its mandatory\n    parameters.\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "iris_dir = os.path.join(kh.get_samples_dir(), \"Iris\")\n",
    "dictionary_file_path = os.path.join(iris_dir, \"Iris.kdic\")\n",
    "data_table_path = os.path.join(iris_dir, \"Iris.txt\")\n",
    "coclustering_report_path = os.path.join(\n",
    "    \"kh_samples\",\n",
    "    \"train_instance_variable_coclustering\",\n",
    "    \"CoclusteringResults.khcj\",\n",
    ")\n",
    "\n",
    "# Train a coclustering model for variables \"SampleId\" and \"Char\"\n",
    "kh.train_instance_variable_coclustering(\n",
    "    dictionary_file_path,\n",
    "    \"Iris\",\n",
    "    data_table_path,\n",
    "    coclustering_report_path,\n",
    ")\n",
    "print(\n",
    "    \"Instance-variable coclustering report file available \"\n",
    "    f\"at {coclustering_report_path}\"\n",
    ")\n",
    "\n",
    "# If you have Khiops Co-Visualization installed you may open the report as follows\n",
    "# kh.visualize_report(coclustering_report_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `simplify_coclustering()`\n\n",
    "Simplifies a coclustering model while preserving 80% of its information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "splice_dir = os.path.join(kh.get_samples_dir(), \"SpliceJunction\")\n",
    "dictionary_file_path = os.path.join(splice_dir, \"SpliceJunction.kdic\")\n",
    "data_table_path = os.path.join(splice_dir, \"SpliceJunctionDNA.txt\")\n",
    "output_dir = os.path.join(\"kh_samples\", \"simplify_coclustering\")\n",
    "coclustering_file_path = os.path.join(output_dir, \"Coclustering.khcj\")\n",
    "simplified_coclustering_file_path = os.path.join(\n",
    "    output_dir, \"simplified_coclustering.khcj\"\n",
    ")\n",
    "\n",
    "# Train coclustering model for variables \"SampleId\" and \"Char\"\n",
    "kh.train_coclustering(\n",
    "    dictionary_file_path,\n",
    "    \"SpliceJunctionDNA\",\n",
    "    data_table_path,\n",
    "    [\"SampleId\", \"Char\"],\n",
    "    coclustering_file_path,\n",
    ")\n",
    "\n",
    "# Simplify the trained coclustering with the constraints\n",
    "# - maximum information preserved: 80%\n",
    "# - maximum total parts number: 4\n",
    "kh.simplify_coclustering(\n",
    "    coclustering_file_path,\n",
    "    simplified_coclustering_file_path,\n",
    "    max_preserved_information=80,\n",
    "    max_total_parts=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `extract_clusters()`\n\n",
    "Extract the clusters' id, members, frequencies and typicalities into a file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file paths\n",
    "splice_dir = os.path.join(kh.get_samples_dir(), \"SpliceJunction\")\n",
    "dictionary_file_path = os.path.join(splice_dir, \"SpliceJunction.kdic\")\n",
    "data_table_path = os.path.join(splice_dir, \"SpliceJunctionDNA.txt\")\n",
    "output_dir = os.path.join(\"kh_samples\", \"extract_clusters\")\n",
    "coclustering_file_path = os.path.join(output_dir, \"Coclustering.khcj\")\n",
    "clusters_file_path = os.path.join(output_dir, \"extracted_clusters.txt\")\n",
    "\n",
    "# Train a coclustering model for variables \"SampleId\" and \"Char\"\n",
    "kh.train_coclustering(\n",
    "    dictionary_file_path,\n",
    "    \"SpliceJunctionDNA\",\n",
    "    data_table_path,\n",
    "    [\"SampleId\", \"Char\"],\n",
    "    coclustering_file_path,\n",
    ")\n",
    "\n",
    "# Extract clusters\n",
    "kh.extract_clusters(coclustering_file_path, \"Char\", clusters_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `deploy_coclustering()`\n\n",
    "Deploys a coclustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the initial file paths\n",
    "splice_dir = os.path.join(kh.get_samples_dir(), \"SpliceJunction\")\n",
    "data_table_path = os.path.join(splice_dir, \"SpliceJunctionDNA.txt\")\n",
    "dictionary_file_path = os.path.join(splice_dir, \"SpliceJunction.kdic\")\n",
    "output_dir = os.path.join(\"kh_samples\", \"deploy_coclustering\")\n",
    "coclustering_file_path = os.path.join(output_dir, \"Coclustering.khcj\")\n",
    "coclustering_dictionary_file_path = os.path.join(output_dir, \"Coclustering.kdic\")\n",
    "output_data_table_path = os.path.join(output_dir, \"DeployedSpliceJunctionDNA.txt\")\n",
    "\n",
    "# Train a coclustering model for variables \"SampleId\" and \"Char\"\n",
    "kh.train_coclustering(\n",
    "    dictionary_file_path,\n",
    "    \"SpliceJunctionDNA\",\n",
    "    data_table_path,\n",
    "    [\"SampleId\", \"Char\"],\n",
    "    coclustering_file_path,\n",
    ")\n",
    "\n",
    "# Deploy \"Char\" clusters in the training database\n",
    "kh.deploy_coclustering(\n",
    "    dictionary_file_path,\n",
    "    \"SpliceJunctionDNA\",\n",
    "    data_table_path,\n",
    "    coclustering_file_path,\n",
    "    [\"SampleId\"],\n",
    "    \"Char\",\n",
    "    coclustering_dictionary_file_path,\n",
    "    output_data_table_path,\n",
    "    header_line=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `deploy_coclustering_expert()`\n\n",
    "Deploys a coclustering step-by-step\n\n    The `.api.prepare_coclustering_deployment` method is called twice to prepare the\n    deployment at two granularity levels. Then, the model is deployed and the respective\n    deployment dictionary is built.\n\n    This is one of the most complex workflows of the Khiops suite.\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the initial file paths\n",
    "splice_dir = os.path.join(kh.get_samples_dir(), \"SpliceJunction\")\n",
    "dictionary_file_path = os.path.join(splice_dir, \"SpliceJunction.kdic\")\n",
    "data_table_path = os.path.join(splice_dir, \"SpliceJunction.txt\")\n",
    "secondary_data_table_path = os.path.join(splice_dir, \"SpliceJunctionDNA.txt\")\n",
    "output_dir = os.path.join(\"kh_samples\", \"deploy_coclustering_expert\")\n",
    "coclustering_file_path = os.path.join(output_dir, \"Coclustering.khcj\")\n",
    "\n",
    "# Train a coclustering model for variables \"SampleId\" and \"Char\"\n",
    "print(\"train coclustering on SpliceJunctionDNA\")\n",
    "kh.train_coclustering(\n",
    "    dictionary_file_path,\n",
    "    \"SpliceJunctionDNA\",\n",
    "    secondary_data_table_path,\n",
    "    [\"SampleId\", \"Char\"],\n",
    "    coclustering_file_path,\n",
    ")\n",
    "\n",
    "print(\"prepare_coclustering_deployment\")\n",
    "# The input dictionary is extended with new coclustering based variables\n",
    "augmented_dictionary_file_path = os.path.join(output_dir, \"Coclustering.kdic\")\n",
    "kh.prepare_coclustering_deployment(\n",
    "    dictionary_file_path,\n",
    "    \"SpliceJunction\",\n",
    "    coclustering_file_path,\n",
    "    \"DNA\",\n",
    "    \"SampleId\",\n",
    "    augmented_dictionary_file_path,\n",
    ")\n",
    "\n",
    "print(\"prepare_coclustering_deployment with at most two clusters\")\n",
    "# Extend the already extended dictionary with the new variables from a simplified CC\n",
    "reaugmented_dictionary_file_path = os.path.join(\n",
    "    output_dir, \"ReaugmentedCoclustering.kdic\"\n",
    ")\n",
    "kh.prepare_coclustering_deployment(\n",
    "    augmented_dictionary_file_path,\n",
    "    \"SpliceJunction\",\n",
    "    coclustering_file_path,\n",
    "    \"DNA\",\n",
    "    \"SampleId\",\n",
    "    reaugmented_dictionary_file_path,\n",
    "    variables_prefix=\"C2_\",\n",
    "    max_part_numbers={\"SampleId\": 2},\n",
    ")\n",
    "\n",
    "output_data_table_path = os.path.join(output_dir, \"TransferredSpliceJunction.txt\")\n",
    "\n",
    "# Deploy the coclustering with the extended dictionary\n",
    "print(\"deploy_model with the new coclustering based variables\")\n",
    "kh.deploy_model(\n",
    "    reaugmented_dictionary_file_path,\n",
    "    \"SpliceJunction\",\n",
    "    data_table_path,\n",
    "    output_data_table_path,\n",
    "    additional_data_tables={\"DNA\": secondary_data_table_path},\n",
    ")\n",
    "\n",
    "deployed_dictionary_file_path = os.path.join(\n",
    "    output_dir, \"Transferred_Coclustering.kdic\"\n",
    ")\n",
    "print(\"build_deployed_dictionary to get the new dictionary\")\n",
    "kh.build_deployed_dictionary(\n",
    "    reaugmented_dictionary_file_path,\n",
    "    \"SpliceJunction\",\n",
    "    deployed_dictionary_file_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `scenario_prologue()`\n\n",
    "Trains a simple model with a prologue written in the Khiops scenario language\n\n    .. note::\n        This is an **advanced** feature.\n    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "dictionary_file_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.kdic\")\n",
    "data_table_path = os.path.join(kh.get_samples_dir(), \"Adult\", \"Adult.txt\")\n",
    "report_file_path = os.path.join(\n",
    "    \"kh_samples\", \"scenario_prologue\", \"AnalysisResults.khj\"\n",
    ")\n",
    "\n",
    "# Set the maximum memory \"by hand\" with an scenario prologue\n",
    "scenario_prologue = \"\"\"\n",
    "    // Max memory 2000 mb\n",
    "    AnalysisSpec.SystemParameters.MemoryLimit 2000\n",
    "    \"\"\"\n",
    "\n",
    "# Train the predictor\n",
    "kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"Adult\",\n",
    "    data_table_path,\n",
    "    \"class\",\n",
    "    report_file_path,\n",
    "    max_trees=0,\n",
    "    scenario_prologue=scenario_prologue,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `build_deployed_dictionary()`\n\n",
    "Builds a dictionary file to read the output table of a deployed model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from khiops import core as kh\n",
    "\n",
    "# Set the file paths\n",
    "dictionary_file_path = os.path.join(kh.get_samples_dir(), \"Iris\", \"Iris.kdic\")\n",
    "data_table_path = os.path.join(kh.get_samples_dir(), \"Iris\", \"Iris.txt\")\n",
    "output_dir = os.path.join(\"kh_samples\", \"build_deployed_dictionary\")\n",
    "deployed_dictionary_file_path = os.path.join(output_dir, \"SNB_Iris_deployed.kdic\")\n",
    "report_file_path = os.path.join(output_dir, \"AnalysisResults.khj\")\n",
    "\n",
    "# Train the predictor\n",
    "_, modeling_dictionary_file_path = kh.train_predictor(\n",
    "    dictionary_file_path,\n",
    "    \"Iris\",\n",
    "    data_table_path,\n",
    "    \"Class\",\n",
    "    report_file_path,\n",
    "    max_trees=0,\n",
    ")\n",
    "\n",
    "# Build the dictionary to read the output of the predictor dictionary file\n",
    "# It will contain the columns of the table generated by deploying the model\n",
    "kh.build_deployed_dictionary(\n",
    "    modeling_dictionary_file_path,\n",
    "    \"SNB_Iris\",\n",
    "    deployed_dictionary_file_path,\n",
    ")\n",
    "\n",
    "# Print the deployed dictionary\n",
    "with open(deployed_dictionary_file_path) as deployed_dictionary_file:\n",
    "    for line in deployed_dictionary_file:\n",
    "        print(line, end=\"\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}